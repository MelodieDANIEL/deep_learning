
.. slide::

Chapitre 4 - Manipulation d'images
================

üéØ Objectifs du Chapitre
----------------------


.. important::

   √Ä la fin de ce chapitre, vous saurez : 

   - Charger, afficher et sauvegarder des fichiers au format image.
   - Manipuler le contenu d'images (redimensionnement, recadrage, rotation, etc.).
   - Faire du slicing sur des tenseurs.
   - Appliquer une convolution 2D sur une image.

.. slide::

üìñ 1. Qu'est-ce qu'une image ?
----------------------

Une image num√©rique est une repr√©sentation discr√®te d'une sc√®ne visuelle. 
Elle est constitu√©e d'une grille de pixels organis√©s en lignes et en colonnes.
La valeur de chaque pixel d√©termine la couleur et la luminosit√© √† cet emplacement pr√©cis de l'image, et peut √™tre donn√© dans diff√©rents espaces colorim√©triques, utilisant un ou plusieurs canaux (channel). Par exemple, une image en niveaux de gris utilise un seul canal, tandis qu'une image en couleur RGB (Red, Green, Blue) utilise trois canaux.

Une image est ainsi repr√©sent√©e par un tableau/tenseur $$H \times W \times C$$ o√π 
- $$H$$ est la hauteur (nombre de lignes), 
- $$W$$ est la largeur (nombre de colonnes) et 
- $$C$$ est le nombre de canaux (1 pour les images en niveaux de gris, 3 pour les images RGB, etc.).

‚ö†Ô∏è En fonction de la biblioth√®que que l'on utilise, une image peut se pr√©senter sous la forme *channel-first* (C, H, W) ou *channel-last* (H, W, C). Ces deux repr√©sentations sont identiques, mais il faut faire attention au format utilis√© avant de r√©aliser des op√©rations matricielles pour lesquelles l'ordre des dimensions est important !

.. figure:: images/image_tensor.png
   :align: center
   :width: 200px
   :alt: Repr√©sentation tensorielle d'une image

   **Figure 1** : Exemple de repr√©sentation tensorielle d'une image (Hauteur √ó Largeur √ó Canaux).

Ainsi, dans une image RGB, chaque pixel a une coordon√©e (y, x) dans $$H \times W$$ qui permet d'acc√©der √† sa couleur encod√©e par trois valeurs : une pour chaque canal R, G et B. Par exemple, un pixel rouge pur aura les valeurs [255, 0, 0] dans un espace colorim√©trique o√π chaque canal varie de 0 √† 255 (i.e., encod√© sur 8 bits). En Machine Learning, il est commun de normaliser ces valeurs de [0; 255] vers [0; 1] (en divisant toutes les valeurs par 255).

D'autres espaces de couleurs existent, comme HSL, HSV, CIELAB...

- **HSL (Hue, Saturation, Lightness)** : HSL d√©compose la couleur en trois composantes : la teinte (Hue, la couleur pure), la saturation (Saturation, l'intensit√© de la couleur) et la luminosit√© (Lightness, la clart√©). Cet espace est utile pour des op√©rations comme le changement de teinte ou l'ajustement de la luminosit√©, car il correspond mieux √† la perception humaine des couleurs.

- **HSV (Hue, Saturation, Value)** : Similaire √† HSL, HSV utilise la teinte, la saturation et la valeur (Value, qui repr√©sente la brillance). Il est souvent utilis√© en traitement d'image pour la segmentation ou le filtrage de couleurs, car il permet de s√©parer facilement la couleur pure de son intensit√©.

- **CIELAB (Lab)** : L'espace CIELAB est con√ßu pour √™tre perceptuellement uniforme, c'est-√†-dire que la distance entre deux couleurs dans cet espace correspond √† la diff√©rence per√ßue par l'≈ìil humain. Il se compose de trois axes : L* (luminosit√©), a* (du vert au rouge), et b* (du bleu au jaune). CIELAB est utilis√© pour des applications o√π la fid√©lit√© de la couleur et la perception humaine sont importantes, comme la retouche photo ou l'impression.

L'int√©r√™t de ces espaces est de faciliter certaines op√©rations sur les couleurs (ajustement de la teinte, segmentation, correction de couleur, etc.) qui seraient complexes ou peu intuitives dans l'espace RGB. Selon le probl√®me √† traiter, choisir l'espace colorim√©trique adapt√© permet d'obtenir de meilleurs r√©sultats et de simplifier les algorithmes.
 
Cependant, RGB ainsi que sa variente RGBA (qui contient un canal Alpha suppl√©mentaire pour encoder la transparence) sont les plus utilis√©s en Machine Learning. Un avantage de RGB est que chaque canal est ind√©pendant des autres, et tous les canaux ont un domaine de valeur identique ([0; 255]).

.. figure:: images/color_spaces.png
   :align: center
   :width: 100%
   :alt: Espaces de couleur

   **Figure 2** : Espaces de couleur RGB, HSL, HSV et CIELAB.

.. slide::
üìñ 2. Le slicing en Python
----------------------
Pour manipuler des sous-parties de tenseurs (et donc d'image), nous avons besoin de s√©lectionner des plages de valeur √† l'int√©rieur de celles-ci. La m√©thode que vous connaissez d√©j√† pour cela est l'utilisation de boucles *for*, avec des indices de d√©but et de fin. Cependant, cette m√©thode est souvent verbeuse, et l'approche it√©rative n'est pas adapt√©e √† l'ex√©cution au GPU.

Le slicing est une technique en Python qui permet d'extraire des sous-parties d'une s√©quence (comme une liste, une cha√Æne de caract√®res ou un tableau) en sp√©cifiant des indices de d√©but, de fin et un pas.
Ici, nous nous concentrerons sur le slicing appliqu√© aux tableaux NumPy qui sont couramment utilis√©s pour repr√©senter des images, et pour lesquelles les op√©rations disponibles sont semblables √† celles des tenseurs PyTorch.

Le slicing en Python utilise la syntaxe suivante : *sequence[start:stop:step]*, o√π :

- *start* est l'indice de d√©but (inclusif),
- *stop* est l'indice de fin (exclusif),
- *step* est le pas (optionnel, par d√©faut 1).
- ' *:* ' est le caract√®re sp√©cial utilis√© comme s√©parateur

.. code-block:: python
   sequence = np.array([0, 1, 2, 3, 4, 5])
   print(sequence[1:6])    # '[1, 2, 3, 4, 5]', affiche de l'indice 1 (inclu) √† l'indice 6 (exclu)
   print(sequence[1:6:2])  # '[1, 3, 5]', affiche de l'indice 1 (inclu) √† l'indice 6 (exclu) avec un pas de 2

Il est √©galement possible d'utiliser les indices n√©gatifs, et il n'est pas n√©cessaire de sp√©cifier tous les param√®tres :

.. code-block:: python
   sequence = np.array([0, 1, 2, 3, 4, 5]))
   print(sequence[2:])  # '[2, 3, 4, 5]', affiche de l'indice 2 (inclu) jusqu'√† la fin
   print(sequence[:4])  # '[0, 1, 2, 3]', affiche du d√©but jusqu'√† l'indice 4 (exclu)
   print(sequence[-3:]) # '[3, 4, 5]', affiche les 3 derniers √©l√©ments

Pour r√©aliser du slicing sur un tenseur (i.e., tableau multidimensionnel), il suffit de s√©parer les indices de chaque dimension par une virgule :
.. code-block:: python
   sequence_2d = np.array([
      [0, 1, 2], 
      [10, 11, 12], 
      [20, 21, 22]
   ])
   print(sequence_2d[:, 0])  # '[0, 10, 20]', affiche la premi√®re colonne de chaque ligne
   print(sequence_2d[0, :])  # '[0, 1, 2]', affiche tous les √©l√©ments de la premi√®re ligne

Une image √©tant un tenseur 3D, le slicing peut √™tre utilis√© pour acc√©der √† des parties sp√©cifiques de l'image, comme une r√©gion rectangulaire ou un canal de couleur particulier : 
.. code-block:: python
   img = np.random.randint(0, 256, (50, 50, 3), dtype=np.uint8)  
   # Image al√©atoire de taille 50x50 avec 3 canaux (RGB)
  
   top_left_10px = img[:10, :10, :]  # S√©lectionne un carr√© de 10x10 pixels √† partir de l'origine (x=0, y=0, par d√©faut en haut √† gauche). 
   # R√©sultat : un tenseur de taille (10, 10, 3)

   red_channel = img[:, :, 0]        # S√©lectionne le premier canal (rouge) de l'image. 
   # R√©sultat : un tenseur de taille (50, 50) ou (50, 50, 1) selon la biblioth√®que utilis√©e

Une image RGB peut ainsi √™tre d√©coup√©e en ses trois canaux de couleur individuels (Rouge, Vert, Bleu) en utilisant le slicing :
.. code-block:: python
   red_channel = img[:, :, 0]   # Canal Rouge
   green_channel = img[:, :, 1] # Canal Vert
   blue_channel = img[:, :, 2]  # Canal Bleu 
   plt.imshow()

.. figure:: images/rgb_channels.png
   :align: center
   :width: 50%
   :alt: Canaux d'une image
   **Figure 3** : S√©paration des canaux Rouge, Vert et Bleu d'une image RGB.
   

.. slide::
üìñ 3. Annotation
----------------------
L'annotation d'images est une √©tape cruciale dans la pr√©paration des donn√©es pour les t√¢ches de vision par ordinateur en apprentissage supervis√©. Elle consiste √† ajouter des informations suppl√©mentaires aux images, telles que des √©tiquettes, des bo√Ætes englobantes, des masques de segmentation, ou des points cl√©s, afin de fournir un contexte et des r√©f√©rences pour l'entra√Ænement des mod√®les.

L'annotation peut √™tre r√©alis√©e manuellement par des annotateurs humains ou automatiquement √† l'aide d'algorithmes, bien que la qualit√© et la pr√©cision des annotations manuelles soient souvent sup√©rieures.

Les types courants d'annotations incluent :

- **Classification** : Attribuer une √©tiquette √† l'ensemble de l'image (par exemple, "chien", "chat", "voiture").

- **D√©tection d'objets** : Dessiner des bo√Ætes englobantes autour des objets d'int√©r√™t dans l'image et attribuer une √©tiquette √† chaque bo√Æte.

- **Segmentation** : Cr√©er des masques qui d√©limitent pr√©cis√©ment les objets dans l'image, pixel par pixel.

- **Points cl√©s** : Marquer des points sp√©cifiques sur les objets, comme les articulations d'un corps humain (d√©tection de plusieurs objets).

L'annotation est essentielle pour entra√Æner des mod√®les de vision par ordinateur, car elle fournit les donn√©es d'entr√©e et les cibles n√©cessaires pour l'apprentissage supervis√©. La qualit√© des annotations a un impact direct sur la performance du mod√®le, et des annotations incorrectes ou incoh√©rentes peuvent entra√Æner des r√©sultats m√©diocres.

.. figure:: images/annot.png
   :align: center
   :width: 100%
   :alt: Annotation d'images
   **Figure 4** : Exemples d'annotations d'images pour diff√©rentes t√¢ches de vision par ordinateur - classification, d√©tection d'objets et segmentation.

.. slide::
üìñ 4. Convolution
----------------------
Une convolution est une op√©ration math√©matique qui applique un filtre (ou noyau, "kernel" en anglais) sur un signal. *Appliquer le filtre* consiste √† faire glisser le noyau sur le signal et √† calculer le produit scalaire entre le noyau et la partie du signal qu'il recouvre.
En Machine Learning, les convolutions sont principalement utilis√©es dans les r√©seaux de neurones convolutifs (CNN pour Convolution Neural Network). Celles-ci permettent de d√©tecter des motifs (contours) et extraire des caract√©ristiques localement dans l'image (un pixel √©tant trait√© avec ses voisins). Ces r√©seaux sont particuli√®rement efficaces pour la classification d'images, la d√©tection d'objets et la segmentation d'images.

.. figure:: images/sig_conv.png
   :align: center
   :width: 400px
   :alt: Convolution signal 1D

   **Figure 5** : Exemple de l'application d'un filtre de convolution sur un signal 1D.

Dans l'exemple ci-dessus : soit le noyau $$a = [1, 2, 1]$$ align√© avec les valeurs $$b = [4, 1, 0]$$ du signal. On applique la formule $$ \sum_{i=0}^{N} a_i*b_i$$, le r√©sultat est donc : $$4*1 + 1*2 + 0*1 = 6$$. 

*Padding* - Comme on peut le voir dans les figures 5 et 6, la taille du signal convolu√© est inf√©rieure √† celle du signal d'origine. Cela est d√ª √† la mani√®re dont le filtre est appliqu√©, en glissant sur le signal et en ne produisant une sortie que lorsque le filtre est compl√®tement superpos√© au signal. Pour compenser cette r√©duction de taille, il est courant d'utiliser un remplissage (padding) qui ajoute des z√©ros autour du signal d'origine avant d'appliquer la convolution.

*Stride* - Le pas (stride) est un autre param√®tre important dans la convolution. Il d√©termine de combien de positions le filtre se d√©place √† chaque √©tape. Un stride de 1 signifie que le filtre se d√©place d'une position √† la fois, tandis qu'un stride de 2 signifie qu'il saute une position entre chaque application. Dans la figure 5, le stride est fix√© √† 1.

Pour convoluer une image, il suffit de reproduire l'op√©ration en 2D. Le noyau est alors une matrice, le padding peut s'appliquer tout autour de l'image, et le stride est en deux dimensions (pas horizontal et vertical).  

.. figure:: images/conv_img.gif
   :align: center
   :width: 300px
   :alt: Convolution image 2D

   **Figure 6** : Exemple de convolution d'une image. L'image est repr√©sent√©e par des carr√©s bleus. Autour de celle-ci, les carr√©s en pointill√©s repr√©sente le remplissage (padding), c'est-√†-dire l'ajout de pixels fictifs tout autour de l'image, et dont la valeur est nulle. Le filtre de convolution est repr√©sent√© en gris et superpos√© √† l'image. Celui-ci glisse sur l'image par pas de 2 verticalement et horizontalement (*stride=(2,2)*). Le signal convolu√© est repr√©sent√© en vert.

En r√©sum√©, une convolution est d√©termin√©e par :

- *kernel* et *kernel_size* : Le noyau de convolution (i.e., sa taille et ses valeurs)
- *stride* : Le pas de l'application du filtre (verticalement et horizontalement)
- *padding* : Le remplissage appliqu√© au signal d'origine

La taille du signal convolu√© est d√©termin√©e par celle de l'image d'origine et de ces trois param√®tres.


.. slide::
üèãÔ∏è Travaux Pratiques
--------------------

.. toctree::

    TP_chap4