.. slide::

Chapitre 5 ‚Äî Techniques avanc√©es et bonnes pratiques PyTorch
================

üéØ Objectifs du Chapitre
----------------------


.. important::

   √Ä la fin de ce chapitre, vous saurez : 

   - Comprendre la diff√©rence entre un MLP et les r√©seaux convolutifs (CNN).
   - Utiliser les couches de convolution pour le traitement d'images.
   - Appliquer les techniques de pooling pour r√©duire la dimensionnalit√©.
   - G√©rer les mini-batchs pour un entra√Ænement efficace.
   - Sauvegarder et charger les poids d'un mod√®le entra√Æn√©.
   - Utiliser les datasets PyTorch pour organiser vos donn√©es.

.. slide::

üìñ 1. MLP vs Convolutions : pourquoi les CNN ?
----------------------

Dans les chapitres pr√©c√©dents, nous avons utilis√© des perceptrons multi-couches (MLP) pour r√©soudre divers probl√®mes. Cependant, lorsqu'on travaille avec des images, les MLP pr√©sentent plusieurs limitations importantes.

1.1. Limitations des MLP pour les images
~~~~~~~~~~~~~~~~~~~

Imaginons une image en couleur de taille $$224√ó224$$ pixels. Si on "aplatit" (avec ``flatten`` par exemple) cette image pour la donner √† un MLP :

- Chaque pixel RGB ‚Üí 3 valeurs
- Total d'entr√©es : $$224 \times 224 \times 3 = 150528$$ valeurs

Si la premi√®re couche cach√©e a 512 neurones :

- Nombre de poids : $$150528 \times 512 = 77070336$$ param√®tres

**Probl√®mes** :

1. **Trop de param√®tres** : le mod√®le devient √©norme, difficile √† entra√Æner et tr√®s gourmand en m√©moire.
2. **Perte de structure spatiale** : en aplatissant l'image, on perd l'information sur la proximit√© des pixels. Or, dans une image, les pixels voisins sont fortement corr√©l√©s.
3. **Pas de g√©n√©ralisation spatiale** : un MLP doit r√©apprendre le m√™me motif s'il appara√Æt √† des positions diff√©rentes dans l'image.

.. slide::

1.2. Solution : les r√©seaux convolutifs (CNN)
~~~~~~~~~~~~~~~~~~~

Les r√©seaux de neurones convolutifs (CNN, de Convolutional Neural Networks en anglais) r√©solvent ces probl√®mes en utilisant des **convolutions** au lieu de couches enti√®rement connect√©es.

1.2.1. Qu'est-ce qu'un filtre (ou noyau de convolution) ?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Un **filtre** (aussi appel√© *kernel* ou *noyau*) est une petite matrice de poids apprenables qui sert √† **d√©tecter des motifs** dans l'image.

- **Taille typique** : $$3√ó3$$, $$5√ó5$$, ou $$7√ó7$$ pixels
- **Fonctionnement** : le filtre "glisse" sur toute l'image (comme un tampon qu'on d√©placerait)
- **D√©tection** : √† chaque position, il calcule une somme pond√©r√©e des pixels qu'il couvre
- **Apprentissage** : les poids du filtre sont appris automatiquement pendant l'entra√Ænement

üí° **Intuition** : imaginez que vous cherchez des visages dans une photo. Vos yeux scannent l'image en cherchant des motifs caract√©ristiques (deux yeux, un nez, une bouche). Les filtres font exactement la m√™me chose, mais de mani√®re automatique et sur des milliers de motifs diff√©rents !

.. slide::
1.2.2. √Ä quoi servent les filtres ?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Chaque filtre est sp√©cialis√© dans la d√©tection d'un type de motif :

- **Contours** : verticaux, horizontaux, diagonaux
- **Textures** : lignes, points, motifs r√©p√©t√©s
- **Formes** : coins, courbes, angles
- **Caract√©ristiques complexes** : yeux, roues, fen√™tres (dans les couches profondes)

Les filtres s'organisent de mani√®re hi√©rarchique :

- **Premi√®res couches** : d√©tectent des caract√©ristiques simples (bords, couleurs)
- **Couches interm√©diaires** : combinent ces caract√©ristiques pour d√©tecter des formes
- **Couches profondes** : d√©tectent des objets complexes (visages, voitures, animaux)

.. slide::
1.2.3. Qu'est-ce qui d√©termine quel filtre fait quoi ?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
C'est l'**entra√Ænement** qui d√©termine la sp√©cialisation de chaque filtre ! Voici comment :

1. **Initialisation al√©atoire** : au d√©part, les poids des filtres sont initialis√©s al√©atoirement (petites valeurs proches de 0).

2. **Apprentissage automatique** : pendant l'entra√Ænement, l'algorithme de descente de gradient ajuste progressivement les poids de chaque filtre pour **minimiser l'erreur** du r√©seau.

3. **Sp√©cialisation √©mergente** : chaque filtre "apprend" naturellement √† d√©tecter les motifs les plus utiles pour la t√¢che. Par exemple :
   
   - Si le r√©seau doit reconna√Ætre des chats, certains filtres apprendront √† d√©tecter des oreilles pointues
   - Si c'est pour des voitures, d'autres d√©tecteront des roues ou des phares

4. **Pas de programmation manuelle** : on ne dit **jamais** explicitement √† un filtre "tu dois d√©tecter les contours verticaux". C'est le r√©seau qui d√©couvre lui-m√™me quels motifs sont importants !

üí° **Analogie** : c'est comme apprendre √† reconna√Ætre des champignons comestibles. Au d√©but, vous ne savez pas quoi regarder. Apr√®s avoir vu des centaines d'exemples, votre cerveau apprend automatiquement √† rep√©rer les indices pertinents (couleur du chapeau, forme du pied, pr√©sence d'un anneau, etc.). Les filtres font exactement pareil !

.. slide::
1.2.4. Avantages des convolutions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

1. **Partage de poids** : le m√™me filtre est appliqu√© sur toute l'image, r√©duisant drastiquement le nombre de param√®tres.
2. **Invariance par translation** : un motif appris √† un endroit peut √™tre d√©tect√© ailleurs dans l'image (un visage reste un visage, qu'il soit en haut √† gauche ou en bas √† droite).
3. **Pr√©servation de la structure spatiale** : les convolutions traitent des r√©gions locales, pr√©servant les relations entre pixels voisins.

**Exemple de gain en param√®tres** :

- Un filtre $$3√ó3$$ sur une image RGB ‚Üí $$3 \times 3 \times 3 = 27$$ poids par filtre
- Avec 64 filtres diff√©rents ‚Üí $$64 \times 27 = 1728$$ param√®tres au total

Compar√© aux 77 millions de param√®tres du MLP, c'est une r√©duction spectaculaire !

.. slide::

üìñ 2. Les couches de convolution dans PyTorch
----------------------

Comme nous l'avons vu au chapitre 4, une convolution 2D applique un filtre sur une image en le faisant glisser sur toute la surface. PyTorch fournit ``nn.Conv2d`` pour cr√©er ces couches convolutives.

2.1. Syntaxe de base
~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   import torch
   import torch.nn as nn

   # Cr√©er une couche de convolution
   conv = nn.Conv2d(
       in_channels=3,      # nombre de canaux en entr√©e (1 pour niveaux de gris, 3 pour RGB, 4 pour RGBA)
       out_channels=64,    # nombre de filtres √† apprendre (64 d√©tecteurs de motifs diff√©rents)
       kernel_size=3,      # taille du filtre 3√ó3 pixels (valeurs courantes : 3, 5, 7, etc.)
       stride=1,           # pas de d√©placement du filtre (un stride de 1 d√©place d'1 pixel √† chaque fois et un stride de 2 divise la taille spatiale par 2)
       padding=1           # ajout de z√©ros autour de l'image pour contr√¥ler la taille de sortie (ajoute 1 pixel de z√©ros autour de l'image pour conserver la taille)
   )

   # Exemple d'utilisation
   x = torch.randn(1, 3, 224, 224)  # batch_size=1, canaux=3, Height=224, Width=224
   y = conv(x)
   print(y.shape)  # torch.Size([1, 64, 224, 224])

.. slide::

2.2. Calcul de la taille de sortie
~~~~~~~~~~~~~~~~~~~

.. math::

   H_{out} = \left\lfloor \frac{H_{in} + 2 \times \text{padding} - \text{kernel_size}}{\text{stride}} \right\rfloor + 1

Avec padding=1, kernel_size=3, stride=1 sur une image 224√ó224 :

.. math::

   H_{out} = \left\lfloor \frac{224 + 2 - 3}{1} \right\rfloor + 1 = 224

La taille spatiale est pr√©serv√©e.

.. slide::

üìñ 3. Pooling : r√©duire la dimensionnalit√©
----------------------

Les couches de pooling permettent de r√©duire progressivement la taille spatiale des repr√©sentations, ce qui :

- **Diminue le nombre de param√®tres et le temps de calcul** : en r√©duisant la taille spatiale (par exemple de 224√ó224 √† 112√ó112), on divise par 4 le nombre de valeurs √† traiter dans les couches suivantes ce qui implique moins de param√®tres et un entra√Ænement plus rapide.
- **Apporte une invariance aux petites translations** : si un motif (par exemple un ≈ìil) se d√©place l√©g√®rement dans l'image (de quelques pixels), le max pooling va quand m√™me d√©tecter la m√™me valeur maximale dans la r√©gion. Cela rend le r√©seau plus robuste aux petits d√©placements des objets
- **Augmente le champ r√©ceptif** : apr√®s un pooling, chaque neurone "voit" une r√©gion plus grande de l'image d'origine, ce qui lui permet de capturer des motifs plus globaux

3.1. Max Pooling
~~~~~~~~~~~~~~~~~~~

Le max pooling prend le maximum dans chaque r√©gion. C'est le type de pooling le plus utilis√©.

.. code-block:: python

   import torch.nn.functional as F

   # Exemple : matrice 4√ó4
   x = torch.tensor([[[[1., 2., 3., 4.],
                       [5., 6., 7., 8.],
                       [9., 10., 11., 12.],
                       [13., 14., 15., 16.]]]])  # [batch=1, canaux=1, height=4, width=4]

   # Max pooling avec kernel 2√ó2 et stride 2
   # kernel_size=2 : on regarde des fen√™tres de 2√ó2 pixels
   # stride=2 : on d√©place la fen√™tre de 2 pixels √† chaque fois (pas de chevauchement)
   y = F.max_pool2d(x, kernel_size=2, stride=2)
   print(y)
   # tensor([[[[ 6.,  8.],
   #           [14., 16.]]]])  # [1, 1, 2, 2] - taille divis√©e par 2

**Explication d√©taill√©e** : 

Le max pooling divise l'image en r√©gions de $$2√ó2$$ pixels et garde seulement le maximum de chaque r√©gion.

**Visualisation des 4 r√©gions** :

.. code-block:: text

   Image d'origine 4√ó4 :
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ  1   2  ‚îÇ  3   4  ‚îÇ  ‚Üí r√©gion 1 : max([1,2,5,6]) = 6
   ‚îÇ  5   6  ‚îÇ  7   8  ‚îÇ  ‚Üí r√©gion 2 : max([3,4,7,8]) = 8
   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
   ‚îÇ  9  10  ‚îÇ 11  12  ‚îÇ  ‚Üí r√©gion 3 : max([9,10,13,14]) = 14
   ‚îÇ 13  14  ‚îÇ 15  16  ‚îÇ  ‚Üí r√©gion 4 : max([11,12,15,16]) = 16
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

   R√©sultat apr√®s max pooling 2√ó2 :
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ  6   8  ‚îÇ
   ‚îÇ 14  16  ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

.. slide::

3.2. Average Pooling
~~~~~~~~~~~~~~~~~~~

L'average pooling calcule la moyenne de chaque r√©gion.

.. code-block:: python

   y = F.avg_pool2d(x, kernel_size=2, stride=2)
   print(y)
   # tensor([[[[ 3.5,  5.5],
   #           [11.5, 13.5]]]])

**Explication** :

- [1,2,5,6] ‚Üí (1+2+5+6)/4 = 3.5
- [3,4,7,8] ‚Üí 5.5
- etc.

.. slide::

3.3. Utilisation dans un r√©seau
~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   class CNNWithPooling(nn.Module):
       def __init__(self):
           super(CNNWithPooling, self).__init__()
           self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
           self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
           self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
           self.fc = nn.Linear(64 * 56 * 56, 10)
       
       def forward(self, x):
           x = F.relu(self.conv1(x))  # [batch, 32, 224, 224]
           x = self.pool(x)            # [batch, 32, 112, 112]
           x = F.relu(self.conv2(x))  # [batch, 64, 112, 112]
           x = self.pool(x)            # [batch, 64, 56, 56]
           x = x.view(x.size(0), -1)
           x = self.fc(x)
           return x

**üí° Astuce** : le max pooling est g√©n√©ralement pr√©f√©r√© car il pr√©serve mieux les caract√©ristiques importantes (contours, textures).

.. slide::

3.4. Exemple complet : CNN avec convolution et pooling
~~~~~~~~~~~~~~~~~~~

Maintenant que nous avons vu les convolutions et le pooling, voici un exemple complet de CNN pour la classification d'images :

.. code-block:: python

   import torch
   import torch.nn as nn
   import torch.nn.functional as F

   class SimpleCNN(nn.Module):
       def __init__(self, num_classes=10):
           super(SimpleCNN, self).__init__()
           
           # Premi√®re couche convolutive : 3 canaux ‚Üí 32 filtres
           self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
           
           # Deuxi√®me couche convolutive : 32 canaux ‚Üí 64 filtres
           self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
           
           # Couches fully-connected pour la classification
           self.fc1 = nn.Linear(64 * 56 * 56, 128)
           self.fc2 = nn.Linear(128, num_classes)
       
       def forward(self, x):
           # x: [batch_size, 3, 224, 224] - image RGB d'entr√©e
           
           # Bloc 1 : Convolution + ReLU + Max Pooling
           x = F.relu(self.conv1(x))      # [batch, 32, 224, 224] - applique 32 filtres
           x = F.max_pool2d(x, 2)          # [batch, 32, 112, 112] - divise la taille par 2
           
           # Bloc 2 : Convolution + ReLU + Max Pooling
           x = F.relu(self.conv2(x))      # [batch, 64, 112, 112] - applique 64 filtres
           x = F.max_pool2d(x, 2)          # [batch, 64, 56, 56] - divise encore par 2
           
           # Aplatir les features maps pour les couches fully-connected
           x = x.view(x.size(0), -1)       # [batch, 64*56*56] = [batch, 200704]
           
           # Classification avec couches fully-connected
           x = F.relu(self.fc1(x))         # [batch, 128]
           x = self.fc2(x)                 # [batch, num_classes] - scores pour chaque classe
           
           return x

   # Cr√©er et tester le mod√®le
   model = SimpleCNN(num_classes=10)
   
   # Afficher l'architecture
   print(model)
   
   # Test avec un batch d'images
   x = torch.randn(4, 3, 224, 224)  # batch de 4 images RGB 224√ó224
   output = model(x)
   print(f"Input shape: {x.shape}")
   print(f"Output shape: {output.shape}")  # torch.Size([4, 10])

**üìä Analyse du mod√®le** :

- **Entr√©e** : images 224√ó224 RGB (3 canaux)
- **Apr√®s conv1 + pool** : 32 feature maps de 112√ó112
- **Apr√®s conv2 + pool** : 64 feature maps de 56√ó56
- **Apr√®s aplatissement** : vecteur de 200 704 valeurs
- **Sortie** : 10 scores (un par classe)

Ce mod√®le r√©duit progressivement la taille spatiale tout en augmentant le nombre de canaux, ce qui est le pattern typique des CNN.

.. slide::

üìñ 4. Mini-batchs : entra√Ænement efficace
----------------------

L'entra√Ænement par mini-batchs est une technique fondamentale en deep learning qui combine les avantages de deux approches extr√™mes.

4.1. Trois approches d'entra√Ænement
~~~~~~~~~~~~~~~~~~~

**1. Batch Gradient Descent (tout le dataset)** :

- Calcule le gradient sur toutes les donn√©es
- Mise √† jour stable mais tr√®s lente
- N√©cessite beaucoup de m√©moire

**2. Stochastic Gradient Descent (SGD, un exemple √† la fois)** :

- Calcule le gradient sur un seul exemple
- Tr√®s rapide mais gradient bruit√©
- Converge de mani√®re erratique

**3. Mini-Batch Gradient Descent** :

- Calcule le gradient sur un petit groupe d'exemples (typiquement 32, 64, 128)
- **Compromis id√©al** : rapide et gradient raisonnablement stable
- Exploite efficacement le parall√©lisme du GPU

.. slide::

4.2. Pourquoi les mini-batchs ?
~~~~~~~~~~~~~~~~~~~

**Avantages** :

1. **Efficacit√© GPU** : les GPUs sont optimis√©s pour traiter plusieurs donn√©es en parall√®le
2. **Estimation du gradient** : le gradient calcul√© sur un mini-batch est une bonne approximation du gradient sur tout le dataset
3. **R√©gularisation** : le bruit dans les mini-batchs peut aider √† √©viter les minima locaux
4. **Gestion m√©moire** : on ne charge qu'une partie du dataset en m√©moire √† la fois

**Choix de la taille** :

- Petits batchs (16-32) : gradient plus bruit√©, convergence plus exploratrice
- Grands batchs (128-256) : gradient plus stable, convergence plus directe
- Compromis courant : 32 ou 64

.. slide::

4.3. Mini-batchs dans PyTorch
~~~~~~~~~~~~~~~~~~~

En PyTorch, tous les tenseurs ont une dimension de batch en premi√®re position :

.. code-block:: python

   # Format attendu : [batch_size, channels, height, width]
   images = torch.randn(32, 3, 224, 224)  # batch de 32 images RGB 224√ó224

   # Les op√©rations sont automatiquement appliqu√©es sur tout le batch
   conv = nn.Conv2d(3, 64, kernel_size=3)
   output = conv(images)  # [32, 64, 222, 222]

**Exemple d'entra√Ænement avec mini-batchs** :

.. code-block:: python

   # Supposons qu'on a des donn√©es et un mod√®le
   model = SimpleCNN()
   optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
   criterion = nn.CrossEntropyLoss()

   # Donn√©es factices
   images = torch.randn(100, 3, 224, 224)
   labels = torch.randint(0, 10, (100,))

   # Param√®tres
   batch_size = 32
   num_batches = len(images) // batch_size

   # Entra√Ænement par mini-batchs
   for epoch in range(10):
       for i in range(num_batches):
           # Extraire un mini-batch
           start_idx = i * batch_size
           end_idx = start_idx + batch_size
           
           batch_images = images[start_idx:end_idx]
           batch_labels = labels[start_idx:end_idx]
           
           # Forward pass
           outputs = model(batch_images)
           loss = criterion(outputs, batch_labels)
           
           # Backward pass et optimisation
           optimizer.zero_grad()
           loss.backward()
           optimizer.step()
       
       print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")

.. slide::

üìñ 5. Datasets et DataLoaders PyTorch
----------------------

G√©rer manuellement les mini-batchs comme ci-dessus devient rapidement fastidieux. PyTorch fournit ``Dataset`` et ``DataLoader`` pour automatiser ce processus.

5.1. La classe Dataset
~~~~~~~~~~~~~~~~~~~

``Dataset`` est une classe abstraite qui repr√©sente votre jeu de donn√©es. Vous devez impl√©menter trois m√©thodes :

.. code-block:: python

   from torch.utils.data import Dataset

   class CustomDataset(Dataset):
       def __init__(self, data, labels):
           # Initialisation du dataset
           self.data = data
           self.labels = labels
       
       def __len__(self):
           # Retourne le nombre total d'exemples
           return len(self.data)
       
       def __getitem__(self, idx):
           # Retourne un exemple √† l'indice idx
           sample = self.data[idx]
           label = self.labels[idx]
           return sample, label

.. slide::

**Exemple concret** :

.. code-block:: python

   import torch
   from torch.utils.data import Dataset

   class SimpleImageDataset(Dataset):
       def __init__(self, num_samples=1000):
           # G√©n√©rer des donn√©es factices
           self.images = torch.randn(num_samples, 3, 64, 64)
           self.labels = torch.randint(0, 10, (num_samples,))
       
       def __len__(self):
           return len(self.images)
       
       def __getitem__(self, idx):
           image = self.images[idx]
           label = self.labels[idx]
           return image, label

   # Cr√©er une instance
   dataset = SimpleImageDataset(num_samples=1000)
   print(f"Nombre d'exemples : {len(dataset)}")
   
   # Acc√©der √† un exemple
   image, label = dataset[0]
   print(f"Shape de l'image : {image.shape}")
   print(f"Label : {label}")

.. slide::

5.2. La classe DataLoader
~~~~~~~~~~~~~~~~~~~

``DataLoader`` encapsule un ``Dataset`` et fournit :

- Le d√©coupage automatique en mini-batchs
- Le m√©lange des donn√©es (shuffle)
- Le chargement parall√®le (multiprocessing)
- La gestion du dernier batch incomplet

.. code-block:: python

   from torch.utils.data import DataLoader

   # Cr√©er le dataset
   dataset = SimpleImageDataset(num_samples=1000)

   # Cr√©er le dataloader
   dataloader = DataLoader(
       dataset,
       batch_size=32,        # taille des batchs
       shuffle=True,         # m√©langer les donn√©es
       num_workers=4,        # nombre de processus pour le chargement
       drop_last=False       # garder ou non le dernier batch incomplet
   )

   # It√©ration sur les batchs
   for batch_idx, (images, labels) in enumerate(dataloader):
       print(f"Batch {batch_idx}: images shape = {images.shape}, labels shape = {labels.shape}")
       # Batch 0: images shape = torch.Size([32, 3, 64, 64]), labels shape = torch.Size([32])

.. slide::

5.3. Exemple complet d'entra√Ænement avec Dataset et DataLoader
~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   import torch
   import torch.nn as nn
   import torch.optim as optim
   from torch.utils.data import Dataset, DataLoader

   # 1. D√©finir le Dataset
   class MyDataset(Dataset):
       def __init__(self, num_samples=1000):
           self.data = torch.randn(num_samples, 3, 64, 64)
           self.labels = torch.randint(0, 10, (num_samples,))
       
       def __len__(self):
           return len(self.data)
       
       def __getitem__(self, idx):
           return self.data[idx], self.labels[idx]

   # 2. Cr√©er les datasets (train et validation)
   train_dataset = MyDataset(num_samples=800)
   val_dataset = MyDataset(num_samples=200)

   # 3. Cr√©er les dataloaders
   train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
   val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

   # 4. D√©finir le mod√®le
   class SimpleCNN(nn.Module):
       def __init__(self):
           super().__init__()
           self.net = nn.Sequential(
               nn.Conv2d(3, 16, kernel_size=3, padding=1),
               nn.ReLU(),
               nn.MaxPool2d(2, 2),
               nn.Conv2d(16, 32, kernel_size=3, padding=1),
               nn.ReLU(),
               nn.MaxPool2d(2, 2),
               nn.Flatten(),
               nn.Linear(32 * 16 * 16, 128),
               nn.ReLU(),
               nn.Linear(128, 10)
           )
       
       def forward(self, x):
           return self.net(x)

   model = SimpleCNN()
   criterion = nn.CrossEntropyLoss()
   optimizer = optim.Adam(model.parameters(), lr=0.001)

   # 5. Boucle d'entra√Ænement
   num_epochs = 5

   for epoch in range(num_epochs):
       # Phase d'entra√Ænement
       model.train()
       train_loss = 0.0
       
       for images, labels in train_loader:
           # Forward
           outputs = model(images)
           loss = criterion(outputs, labels)
           
           # Backward
           optimizer.zero_grad()
           loss.backward()
           optimizer.step()
           
           train_loss += loss.item()
       
       # Phase de validation
       model.eval()
       val_loss = 0.0
       correct = 0
       total = 0
       
       with torch.no_grad():
           for images, labels in val_loader:
               outputs = model(images)
               loss = criterion(outputs, labels)
               val_loss += loss.item()
               
               _, predicted = torch.max(outputs, 1)
               total += labels.size(0)
               correct += (predicted == labels).sum().item()
       
       # Affichage
       print(f"Epoch {epoch+1}/{num_epochs}")
       print(f"  Train Loss: {train_loss/len(train_loader):.4f}")
       print(f"  Val Loss: {val_loss/len(val_loader):.4f}")
       print(f"  Val Accuracy: {100*correct/total:.2f}%")

.. slide::

5.4. Datasets PyTorch int√©gr√©s
~~~~~~~~~~~~~~~~~~~

PyTorch fournit de nombreux datasets pr√™ts √† l'emploi dans ``torchvision.datasets`` :

.. code-block:: python

   from torchvision import datasets, transforms

   # MNIST (chiffres manuscrits)
   mnist_train = datasets.MNIST(
       root='./data',
       train=True,
       download=True,
       transform=transforms.ToTensor()
   )

   # CIFAR-10 (images naturelles, 10 classes)
   cifar_train = datasets.CIFAR10(
       root='./data',
       train=True,
       download=True,
       transform=transforms.ToTensor()
   )

   # Cr√©er un DataLoader
   train_loader = DataLoader(mnist_train, batch_size=64, shuffle=True)

   # Utilisation
   for images, labels in train_loader:
       print(images.shape)  # torch.Size([64, 1, 28, 28]) pour MNIST
       break

.. slide::

üìñ 6. Sauvegarder et charger les poids d'un mod√®le
----------------------

Apr√®s avoir entra√Æn√© un mod√®le pendant des heures (voire des jours), il est essentiel de pouvoir sauvegarder son √©tat pour le r√©utiliser plus tard sans avoir √† tout r√©-entra√Æner.

6.1. Sauvegarder un mod√®le complet
~~~~~~~~~~~~~~~~~~~

PyTorch offre deux approches pour sauvegarder un mod√®le :

**M√©thode 1 : Sauvegarder tout le mod√®le**

.. code-block:: python

   import torch

   # Entra√Ænement du mod√®le
   model = SimpleCNN()
   # ... entra√Ænement ...

   # Sauvegarder le mod√®le complet
   torch.save(model, 'model_complet.pth')

   # Charger le mod√®le complet
   model_charge = torch.load('model_complet.pth')
   model_charge.eval()  # passer en mode √©valuation

**‚ö†Ô∏è Attention** : cette m√©thode sauvegarde toute la structure du mod√®le. Si vous modifiez la d√©finition de la classe, le chargement peut √©chouer.

.. slide::

6.2. Sauvegarder uniquement les poids (m√©thode recommand√©e)
~~~~~~~~~~~~~~~~~~~

**M√©thode 2 : Sauvegarder uniquement les param√®tres (state_dict)**

.. code-block:: python

   # Sauvegarder uniquement les poids
   torch.save(model.state_dict(), 'model_weights.pth')

   # Charger les poids
   model = SimpleCNN()  # cr√©er d'abord une instance du mod√®le
   model.load_state_dict(torch.load('model_weights.pth'))
   model.eval()

**üí° Avantages** :

- Plus flexible : on peut modifier l√©g√®rement l'architecture
- Fichier plus l√©ger
- Meilleure pratique recommand√©e par PyTorch

.. slide::

6.3. Sauvegarder l'√©tat complet de l'entra√Ænement
~~~~~~~~~~~~~~~~~~~

Pour reprendre l'entra√Ænement exactement o√π vous l'aviez arr√™t√©, sauvegardez √©galement l'optimiseur et l'epoch :

.. code-block:: python

   # Sauvegarder tout l'√©tat d'entra√Ænement
   checkpoint = {
       'epoch': epoch,
       'model_state_dict': model.state_dict(),
       'optimizer_state_dict': optimizer.state_dict(),
       'loss': loss,
   }
   torch.save(checkpoint, 'checkpoint.pth')

   # Charger et reprendre l'entra√Ænement
   model = SimpleCNN()
   optimizer = torch.optim.Adam(model.parameters())

   checkpoint = torch.load('checkpoint.pth')
   model.load_state_dict(checkpoint['model_state_dict'])
   optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
   start_epoch = checkpoint['epoch']
   loss = checkpoint['loss']

   model.train()  # reprendre l'entra√Ænement

.. slide::

6.4. Exemple complet avec sauvegarde automatique
~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   import torch
   import torch.nn as nn
   import torch.optim as optim
   from torch.utils.data import DataLoader
   import os

   # Configuration
   model = SimpleCNN()
   optimizer = optim.Adam(model.parameters(), lr=0.001)
   criterion = nn.CrossEntropyLoss()
   train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

   # Cr√©er un dossier pour les checkpoints
   os.makedirs('checkpoints', exist_ok=True)

   # Variables pour sauvegarder le meilleur mod√®le
   best_val_loss = float('inf')

   # Entra√Ænement avec sauvegarde
   for epoch in range(num_epochs):
       model.train()
       train_loss = 0.0
       
       for images, labels in train_loader:
           outputs = model(images)
           loss = criterion(outputs, labels)
           
           optimizer.zero_grad()
           loss.backward()
           optimizer.step()
           
           train_loss += loss.item()
       
       # Validation
       model.eval()
       val_loss = 0.0
       with torch.no_grad():
           for images, labels in val_loader:
               outputs = model(images)
               loss = criterion(outputs, labels)
               val_loss += loss.item()
       
       val_loss /= len(val_loader)
       
       # Sauvegarder si c'est le meilleur mod√®le
       if val_loss < best_val_loss:
           best_val_loss = val_loss
           torch.save({
               'epoch': epoch,
               'model_state_dict': model.state_dict(),
               'optimizer_state_dict': optimizer.state_dict(),
               'val_loss': val_loss,
           }, 'checkpoints/best_model.pth')
           print(f"‚úì Nouveau meilleur mod√®le sauvegard√© (val_loss: {val_loss:.4f})")
       
       # Sauvegarder un checkpoint r√©gulier tous les 10 epochs
       if (epoch + 1) % 10 == 0:
           torch.save({
               'epoch': epoch,
               'model_state_dict': model.state_dict(),
               'optimizer_state_dict': optimizer.state_dict(),
           }, f'checkpoints/checkpoint_epoch_{epoch+1}.pth')

   print(f"Entra√Ænement termin√©. Meilleure val_loss: {best_val_loss:.4f}")

.. slide::

6.5. Utiliser un mod√®le sauvegard√© pour l'inf√©rence
~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   import torch

   # D√©finir la classe du mod√®le (doit √™tre identique)
   class SimpleCNN(nn.Module):
       # ... d√©finition du mod√®le ...
       pass

   # Charger le meilleur mod√®le
   model = SimpleCNN()
   checkpoint = torch.load('checkpoints/best_model.pth')
   model.load_state_dict(checkpoint['model_state_dict'])
   model.eval()

   # Passer le mod√®le sur GPU si disponible
   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
   model = model.to(device)

   # Faire des pr√©dictions
   with torch.no_grad():
       for images, labels in test_loader:
           images = images.to(device)
           outputs = model(images)
           _, predicted = torch.max(outputs, 1)
           # ... traiter les pr√©dictions ...

.. slide::

üìñ 7. R√©capitulatif et bonnes pratiques
----------------------

7.1. Pipeline complet d'entra√Ænement
~~~~~~~~~~~~~~~~~~~

Voici le pipeline standard pour entra√Æner un CNN avec toutes les techniques vues :

.. code-block:: python

   import torch
   import torch.nn as nn
   import torch.optim as optim
   from torch.utils.data import Dataset, DataLoader
   import os

   # 1. D√©finir le Dataset
   class CustomDataset(Dataset):
       def __init__(self, data_path, transform=None):
           # Charger vos donn√©es
           pass
       
       def __len__(self):
           return len(self.data)
       
       def __getitem__(self, idx):
           return self.data[idx], self.labels[idx]

   # 2. D√©finir le mod√®le avec convolutions et pooling
   class CNN(nn.Module):
       def __init__(self, num_classes):
           super(CNN, self).__init__()
           self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
           self.pool = nn.MaxPool2d(2, 2)
           self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
           self.fc = nn.Linear(64 * 16 * 16, num_classes)
       
       def forward(self, x):
           x = self.pool(torch.relu(self.conv1(x)))
           x = self.pool(torch.relu(self.conv2(x)))
           x = x.view(x.size(0), -1)
           x = self.fc(x)
           return x

   # 3. Pr√©parer les donn√©es avec DataLoader
   train_dataset = CustomDataset('train_data')
   train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
   
   val_dataset = CustomDataset('val_data')
   val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

   # 4. Initialiser le mod√®le, la loss et l'optimiseur
   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
   model = CNN(num_classes=10).to(device)
   criterion = nn.CrossEntropyLoss()
   optimizer = optim.Adam(model.parameters(), lr=0.001)

   # 5. Cr√©er un dossier pour les sauvegardes
   os.makedirs('checkpoints', exist_ok=True)
   best_val_loss = float('inf')

   # 6. Boucle d'entra√Ænement
   num_epochs = 50
   
   for epoch in range(num_epochs):
       # PHASE D'ENTRA√éNEMENT
       model.train()
       train_loss = 0.0
       
       for batch_idx, (images, labels) in enumerate(train_loader):
           images, labels = images.to(device), labels.to(device)
           
           # Forward pass
           outputs = model(images)
           loss = criterion(outputs, labels)
           
           # Backward pass et optimisation
           optimizer.zero_grad()
           loss.backward()
           optimizer.step()
           
           train_loss += loss.item()
       
       # PHASE DE VALIDATION
       model.eval()
       val_loss = 0.0
       correct = 0
       total = 0
       
       with torch.no_grad():
           for images, labels in val_loader:
               images, labels = images.to(device), labels.to(device)
               outputs = model(images)
               loss = criterion(outputs, labels)
               val_loss += loss.item()
               
               _, predicted = torch.max(outputs, 1)
               total += labels.size(0)
               correct += (predicted == labels).sum().item()
       
       # Calcul des moyennes
       train_loss /= len(train_loader)
       val_loss /= len(val_loader)
       val_acc = 100 * correct / total
       
       print(f"Epoch [{epoch+1}/{num_epochs}]")
       print(f"  Train Loss: {train_loss:.4f}")
       print(f"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
       
       # Sauvegarder le meilleur mod√®le
       if val_loss < best_val_loss:
           best_val_loss = val_loss
           torch.save({
               'epoch': epoch,
               'model_state_dict': model.state_dict(),
               'optimizer_state_dict': optimizer.state_dict(),
               'val_loss': val_loss,
               'val_acc': val_acc,
           }, 'checkpoints/best_model.pth')
           print(f"  ‚úì Meilleur mod√®le sauvegard√©!")

   print("Entra√Ænement termin√©!")

.. slide::

7.2. Bonnes pratiques
~~~~~~~~~~~~~~~~~~~

**Organisation des donn√©es** :

1. Toujours s√©parer train/validation/test
2. Utiliser ``Dataset`` et ``DataLoader`` pour g√©rer les donn√©es
3. Appliquer les transformations (normalisation, augmentation) dans le ``Dataset``

**Architecture du mod√®le** :

1. Utiliser des convolutions pour les images (pas de MLP)
2. Alterner convolutions et pooling pour r√©duire progressivement la taille
3. Ajouter du batch normalization pour stabiliser l'entra√Ænement
4. Utiliser ReLU comme activation dans les couches cach√©es

**Entra√Ænement** :

1. Utiliser des mini-batchs (taille typique : 32-64)
2. Shuffler les donn√©es d'entra√Ænement (``shuffle=True``)
3. Ne PAS shuffler les donn√©es de validation/test
4. Utiliser ``model.train()`` pour l'entra√Ænement et ``model.eval()`` pour l'√©valuation
5. Utiliser ``torch.no_grad()`` pendant la validation pour √©conomiser la m√©moire

**Sauvegarde** :

1. Sauvegarder le meilleur mod√®le bas√© sur la validation loss
2. Sauvegarder r√©guli√®rement des checkpoints pour pouvoir reprendre
3. Pr√©f√©rer ``state_dict()`` √† sauvegarder le mod√®le entier

.. slide::

7.3. Checklist avant de lancer un entra√Ænement
~~~~~~~~~~~~~~~~~~~

‚úÖ **Donn√©es** :

- [ ] Dataset impl√©ment√© correctement (``__len__`` et ``__getitem__``)
- [ ] Donn√©es normalis√©es (mean=0, std=1)
- [ ] Train/val/test bien s√©par√©s
- [ ] DataLoader cr√©√©s avec la bonne batch_size

‚úÖ **Mod√®le** :

- [ ] Architecture adapt√©e au probl√®me
- [ ] Mod√®le d√©plac√© sur le bon device (CPU/GPU)
- [ ] Taille des tenseurs v√©rifi√©e √† chaque couche

‚úÖ **Entra√Ænement** :

- [ ] Loss function appropri√©e
- [ ] Optimiseur configur√© avec un bon learning rate
- [ ] ``optimizer.zero_grad()`` appel√© avant chaque backward
- [ ] ``model.train()`` et ``model.eval()`` utilis√©s correctement

‚úÖ **Monitoring** :

- [ ] Loss affich√©e r√©guli√®rement
- [ ] M√©triques de validation calcul√©es
- [ ] Meilleur mod√®le sauvegard√©

.. slide::

üèãÔ∏è Travaux Pratiques 5
--------------------

.. toctree::

    TP_chap5





#######################################################################
########################Stop ici pour le moment########################
########################Stop ici pour le moment########################
########################Stop ici pour le moment########################
#######################################################################