.. slide::

TP Chapitre 5 - Classification d'images avec CNN
================

üéØ Objectifs du TP
----------------------

.. important::

   Dans ce TP, vous allez :

   - Impl√©menter un r√©seau de neurones convolutif (CNN)
   - Utiliser les datasets et dataloaders PyTorch
   - Entra√Æner un mod√®le sur le dataset CIFAR-10
   - Comparer les performances d'un MLP et d'un CNN
   - Sauvegarder et charger des mod√®les entra√Æn√©s
   - Exp√©rimenter avec diff√©rentes architectures

.. slide::

üìã Exercice 1 : Pr√©paration des donn√©es (üçÄ)
----------------------

**Objectif** : Charger et pr√©parer le dataset CIFAR-10

CIFAR-10 est un dataset c√©l√®bre contenant 60 000 images couleur 32√ó32 r√©parties en 10 classes :
avion, voiture, oiseau, chat, cerf, chien, grenouille, cheval, bateau, camion.

1.1. Charger CIFAR-10
~~~~~~~~~~~~~~~~~~~

Cr√©ez un fichier ``tp5_preparation.py`` et impl√©mentez le code suivant :

.. code-block:: python

   import torch
   import torchvision
   import torchvision.transforms as transforms
   import matplotlib.pyplot as plt
   import numpy as np

   # Transformations pour normaliser les donn√©es
   transform = transforms.Compose([
       transforms.ToTensor(),
       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
   ])

   # T√©l√©charger et charger les donn√©es d'entra√Ænement
   trainset = torchvision.datasets.CIFAR10(
       root='./data',
       train=True,
       download=True,
       transform=transform
   )

   # T√©l√©charger et charger les donn√©es de test
   testset = torchvision.datasets.CIFAR10(
       root='./data',
       train=False,
       download=True,
       transform=transform
   )

   # Cr√©er les DataLoaders
   trainloader = torch.utils.data.DataLoader(
       trainset,
       batch_size=64,
       shuffle=True,
       num_workers=2
   )

   testloader = torch.utils.data.DataLoader(
       testset,
       batch_size=64,
       shuffle=False,
       num_workers=2
   )

   # Les 10 classes de CIFAR-10
   classes = ('avion', 'voiture', 'oiseau', 'chat', 'cerf',
              'chien', 'grenouille', 'cheval', 'bateau', 'camion')

   print(f"Nombre d'images d'entra√Ænement : {len(trainset)}")
   print(f"Nombre d'images de test : {len(testset)}")

.. slide::

1.2. Visualiser les donn√©es
~~~~~~~~~~~~~~~~~~~

Ajoutez une fonction pour visualiser quelques images :

.. code-block:: python

   def imshow(img):
       """Fonction pour afficher une image"""
       img = img / 2 + 0.5     # d√©normaliser
       npimg = img.numpy()
       plt.imshow(np.transpose(npimg, (1, 2, 0)))
       plt.show()

   # Obtenir un batch d'images d'entra√Ænement
   dataiter = iter(trainloader)
   images, labels = next(dataiter)

   # Afficher les images
   imshow(torchvision.utils.make_grid(images[:8]))
   # Afficher les labels
   print(' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))

**Questions** :

1. Quelle est la forme d'un batch d'images ?
2. Pourquoi normalise-t-on les images avec ``(0.5, 0.5, 0.5)`` pour la moyenne et l'√©cart-type ?
3. Que fait la transformation ``ToTensor()`` ?

.. slide::

üìã Exercice 2 : MLP de base (üçÄ)
----------------------

**Objectif** : Cr√©er un perceptron multi-couches pour servir de r√©f√©rence

2.1. Impl√©menter un MLP
~~~~~~~~~~~~~~~~~~~

Cr√©ez un fichier ``tp5_mlp.py`` avec le code suivant :

.. code-block:: python

   import torch
   import torch.nn as nn
   import torch.nn.functional as F

   class SimpleMLP(nn.Module):
       def __init__(self):
           super(SimpleMLP, self).__init__()
           # Une image CIFAR-10 fait 32x32x3 = 3072 pixels
           self.fc1 = nn.Linear(3 * 32 * 32, 512)
           self.fc2 = nn.Linear(512, 256)
           self.fc3 = nn.Linear(256, 10)  # 10 classes
       
       def forward(self, x):
           # Aplatir l'image
           x = x.view(-1, 3 * 32 * 32)
           
           x = F.relu(self.fc1(x))
           x = F.relu(self.fc2(x))
           x = self.fc3(x)
           return x

   # Cr√©er le mod√®le
   model_mlp = SimpleMLP()
   print(model_mlp)

   # Compter le nombre de param√®tres
   total_params = sum(p.numel() for p in model_mlp.parameters())
   print(f"\nNombre total de param√®tres : {total_params:,}")

**√Ä faire** :

1. Ex√©cutez le code et notez le nombre de param√®tres
2. Calculez manuellement le nombre de param√®tres de la premi√®re couche

.. slide::

2.2. Entra√Æner le MLP
~~~~~~~~~~~~~~~~~~~

Ajoutez le code d'entra√Ænement :

.. code-block:: python

   import torch.optim as optim
   from tp5_preparation import trainloader, testloader

   # Configuration
   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
   model_mlp = SimpleMLP().to(device)
   criterion = nn.CrossEntropyLoss()
   optimizer = optim.Adam(model_mlp.parameters(), lr=0.001)

   # Entra√Ænement
   num_epochs = 10

   for epoch in range(num_epochs):
       model_mlp.train()
       running_loss = 0.0
       correct = 0
       total = 0
       
       for i, (images, labels) in enumerate(trainloader):
           images, labels = images.to(device), labels.to(device)
           
           # Forward
           outputs = model_mlp(images)
           loss = criterion(outputs, labels)
           
           # Backward
           optimizer.zero_grad()
           loss.backward()
           optimizer.step()
           
           # Statistiques
           running_loss += loss.item()
           _, predicted = torch.max(outputs, 1)
           total += labels.size(0)
           correct += (predicted == labels).sum().item()
       
       train_acc = 100 * correct / total
       print(f"Epoch [{epoch+1}/{num_epochs}], "
             f"Loss: {running_loss/len(trainloader):.4f}, "
             f"Train Acc: {train_acc:.2f}%")

   # Sauvegarder le mod√®le
   torch.save(model_mlp.state_dict(), 'mlp_cifar10.pth')
   print("Mod√®le MLP sauvegard√©!")

.. slide::

2.3. √âvaluer le MLP
~~~~~~~~~~~~~~~~~~~

Ajoutez la fonction d'√©valuation :

.. code-block:: python

   def evaluate_model(model, dataloader, device):
       """√âvalue le mod√®le sur un dataset"""
       model.eval()
       correct = 0
       total = 0
       
       with torch.no_grad():
           for images, labels in dataloader:
               images, labels = images.to(device), labels.to(device)
               outputs = model(images)
               _, predicted = torch.max(outputs, 1)
               total += labels.size(0)
               correct += (predicted == labels).sum().item()
       
       accuracy = 100 * correct / total
       return accuracy

   # √âvaluer sur le test set
   test_acc = evaluate_model(model_mlp, testloader, device)
   print(f"Pr√©cision sur le test set : {test_acc:.2f}%")

**Questions** :

1. Quelle pr√©cision obtenez-vous apr√®s 10 epochs ?
2. Le mod√®le semble-t-il sur-apprendre (overfitting) ?
3. Combien de temps prend une epoch ?

.. slide::

üìã Exercice 3 : Premier CNN simple (‚öñÔ∏è)
----------------------

**Objectif** : Cr√©er un r√©seau convolutif et comparer avec le MLP

3.1. Impl√©menter un CNN simple
~~~~~~~~~~~~~~~~~~~

Cr√©ez un fichier ``tp5_cnn.py`` :

.. code-block:: python

   import torch
   import torch.nn as nn
   import torch.nn.functional as F

   class SimpleCNN(nn.Module):
       def __init__(self):
           super(SimpleCNN, self).__init__()
           # Couches de convolution
           self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
           self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
           self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)
           
           # Pooling
           self.pool = nn.MaxPool2d(2, 2)
           
           # Couches fully-connected
           # Apr√®s 3 poolings : 32 -> 16 -> 8 -> 4
           self.fc1 = nn.Linear(64 * 4 * 4, 512)
           self.fc2 = nn.Linear(512, 10)
           
           # Dropout pour la r√©gularisation
           self.dropout = nn.Dropout(0.5)
       
       def forward(self, x):
           # Block 1
           x = F.relu(self.conv1(x))       # [batch, 32, 32, 32]
           x = self.pool(x)                 # [batch, 32, 16, 16]
           
           # Block 2
           x = F.relu(self.conv2(x))       # [batch, 64, 16, 16]
           x = self.pool(x)                 # [batch, 64, 8, 8]
           
           # Block 3
           x = F.relu(self.conv3(x))       # [batch, 64, 8, 8]
           x = self.pool(x)                 # [batch, 64, 4, 4]
           
           # Aplatir
           x = x.view(-1, 64 * 4 * 4)
           
           # Fully-connected
           x = F.relu(self.fc1(x))
           x = self.dropout(x)
           x = self.fc2(x)
           
           return x

   # Cr√©er le mod√®le
   model_cnn = SimpleCNN()
   print(model_cnn)

   # Compter les param√®tres
   total_params = sum(p.numel() for p in model_cnn.parameters())
   print(f"\nNombre total de param√®tres : {total_params:,}")

**√Ä faire** :

1. Comparez le nombre de param√®tres avec le MLP
2. Ajoutez des commentaires pour indiquer la taille des tenseurs √† chaque √©tape

.. slide::

3.2. Entra√Æner le CNN
~~~~~~~~~~~~~~~~~~~

Ajoutez le code d'entra√Ænement (similaire au MLP) :

.. code-block:: python

   import torch.optim as optim
   from tp5_preparation import trainloader, testloader
   from tp5_mlp import evaluate_model

   # Configuration
   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
   model_cnn = SimpleCNN().to(device)
   criterion = nn.CrossEntropyLoss()
   optimizer = optim.Adam(model_cnn.parameters(), lr=0.001)

   # Entra√Ænement
   num_epochs = 20

   for epoch in range(num_epochs):
       model_cnn.train()
       running_loss = 0.0
       correct = 0
       total = 0
       
       for images, labels in trainloader:
           images, labels = images.to(device), labels.to(device)
           
           outputs = model_cnn(images)
           loss = criterion(outputs, labels)
           
           optimizer.zero_grad()
           loss.backward()
           optimizer.step()
           
           running_loss += loss.item()
           _, predicted = torch.max(outputs, 1)
           total += labels.size(0)
           correct += (predicted == labels).sum().item()
       
       train_acc = 100 * correct / total
       
       # √âvaluation sur le test set
       test_acc = evaluate_model(model_cnn, testloader, device)
       
       print(f"Epoch [{epoch+1}/{num_epochs}], "
             f"Loss: {running_loss/len(trainloader):.4f}, "
             f"Train Acc: {train_acc:.2f}%, "
             f"Test Acc: {test_acc:.2f}%")

   # Sauvegarder le mod√®le
   torch.save(model_cnn.state_dict(), 'cnn_cifar10.pth')
   print("Mod√®le CNN sauvegard√©!")

**Questions** :

1. Comparez la pr√©cision du CNN avec celle du MLP
2. Le CNN apprend-il plus vite que le MLP ?
3. Y a-t-il du sur-apprentissage ? Comment le d√©tecter ?

.. slide::

üìã Exercice 4 : Dataset personnalis√© (‚öñÔ∏è)
----------------------

**Objectif** : Cr√©er un Dataset PyTorch pour s√©parer train/validation

4.1. Impl√©menter un Dataset avec split train/val
~~~~~~~~~~~~~~~~~~~

Cr√©ez un fichier ``tp5_dataset.py`` :

.. code-block:: python

   import torch
   from torch.utils.data import Dataset, DataLoader, random_split
   import torchvision
   import torchvision.transforms as transforms

   # Charger CIFAR-10 complet
   transform = transforms.Compose([
       transforms.ToTensor(),
       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
   ])

   full_trainset = torchvision.datasets.CIFAR10(
       root='./data',
       train=True,
       download=True,
       transform=transform
   )

   testset = torchvision.datasets.CIFAR10(
       root='./data',
       train=False,
       download=True,
       transform=transform
   )

   # S√©parer train et validation (80/20)
   train_size = int(0.8 * len(full_trainset))
   val_size = len(full_trainset) - train_size

   trainset, valset = random_split(
       full_trainset,
       [train_size, val_size],
       generator=torch.Generator().manual_seed(42)  # pour la reproductibilit√©
   )

   print(f"Train set : {len(trainset)} images")
   print(f"Validation set : {len(valset)} images")
   print(f"Test set : {len(testset)} images")

   # Cr√©er les DataLoaders
   trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)
   valloader = DataLoader(valset, batch_size=64, shuffle=False, num_workers=2)
   testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)

.. slide::

4.2. Entra√Æner avec validation
~~~~~~~~~~~~~~~~~~~

Modifiez la boucle d'entra√Ænement pour inclure la validation :

.. code-block:: python

   from tp5_dataset import trainloader, valloader, testloader
   from tp5_cnn import SimpleCNN
   from tp5_mlp import evaluate_model
   import torch
   import torch.nn as nn
   import torch.optim as optim

   # Configuration
   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
   model = SimpleCNN().to(device)
   criterion = nn.CrossEntropyLoss()
   optimizer = optim.Adam(model.parameters(), lr=0.001)

   # Pour sauvegarder le meilleur mod√®le
   best_val_acc = 0.0

   # Entra√Ænement avec validation
   num_epochs = 20

   for epoch in range(num_epochs):
       # PHASE D'ENTRA√éNEMENT
       model.train()
       train_loss = 0.0
       train_correct = 0
       train_total = 0
       
       for images, labels in trainloader:
           images, labels = images.to(device), labels.to(device)
           
           outputs = model(images)
           loss = criterion(outputs, labels)
           
           optimizer.zero_grad()
           loss.backward()
           optimizer.step()
           
           train_loss += loss.item()
           _, predicted = torch.max(outputs, 1)
           train_total += labels.size(0)
           train_correct += (predicted == labels).sum().item()
       
       train_acc = 100 * train_correct / train_total
       
       # PHASE DE VALIDATION
       val_acc = evaluate_model(model, valloader, device)
       
       # Sauvegarder le meilleur mod√®le
       if val_acc > best_val_acc:
           best_val_acc = val_acc
           torch.save({
               'epoch': epoch,
               'model_state_dict': model.state_dict(),
               'optimizer_state_dict': optimizer.state_dict(),
               'val_acc': val_acc,
           }, 'best_cnn_cifar10.pth')
           print(f"‚úì Nouveau meilleur mod√®le sauvegard√©! Val Acc: {val_acc:.2f}%")
       
       print(f"Epoch [{epoch+1}/{num_epochs}], "
             f"Loss: {train_loss/len(trainloader):.4f}, "
             f"Train Acc: {train_acc:.2f}%, "
             f"Val Acc: {val_acc:.2f}%")

   # √âvaluer sur le test set avec le meilleur mod√®le
   checkpoint = torch.load('best_cnn_cifar10.pth')
   model.load_state_dict(checkpoint['model_state_dict'])
   test_acc = evaluate_model(model, testloader, device)
   print(f"\nPr√©cision finale sur le test set : {test_acc:.2f}%")

.. slide::

üìã Exercice 5 : CNN am√©lior√© (üå∂Ô∏è)
----------------------

**Objectif** : Am√©liorer l'architecture avec des techniques avanc√©es

5.1. CNN avec Batch Normalization
~~~~~~~~~~~~~~~~~~~

Cr√©ez un fichier ``tp5_cnn_advanced.py`` :

.. code-block:: python

   import torch
   import torch.nn as nn
   import torch.nn.functional as F

   class ImprovedCNN(nn.Module):
       def __init__(self):
           super(ImprovedCNN, self).__init__()
           
           # Block 1
           self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
           self.bn1 = nn.BatchNorm2d(32)
           
           # Block 2
           self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
           self.bn2 = nn.BatchNorm2d(64)
           
           # Block 3
           self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
           self.bn3 = nn.BatchNorm2d(128)
           
           # Block 4
           self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)
           self.bn4 = nn.BatchNorm2d(128)
           
           # Pooling
           self.pool = nn.MaxPool2d(2, 2)
           
           # Fully-connected
           self.fc1 = nn.Linear(128 * 2 * 2, 512)
           self.bn_fc = nn.BatchNorm1d(512)
           self.fc2 = nn.Linear(512, 10)
           
           # Dropout
           self.dropout = nn.Dropout(0.5)
       
       def forward(self, x):
           # Block 1: [batch, 3, 32, 32] -> [batch, 32, 16, 16]
           x = self.conv1(x)
           x = self.bn1(x)
           x = F.relu(x)
           x = self.pool(x)
           
           # Block 2: [batch, 32, 16, 16] -> [batch, 64, 8, 8]
           x = self.conv2(x)
           x = self.bn2(x)
           x = F.relu(x)
           x = self.pool(x)
           
           # Block 3: [batch, 64, 8, 8] -> [batch, 128, 4, 4]
           x = self.conv3(x)
           x = self.bn3(x)
           x = F.relu(x)
           x = self.pool(x)
           
           # Block 4: [batch, 128, 4, 4] -> [batch, 128, 2, 2]
           x = self.conv4(x)
           x = self.bn4(x)
           x = F.relu(x)
           x = self.pool(x)
           
           # Flatten
           x = x.view(x.size(0), -1)
           
           # FC layers
           x = self.fc1(x)
           x = self.bn_fc(x)
           x = F.relu(x)
           x = self.dropout(x)
           x = self.fc2(x)
           
           return x

   model = ImprovedCNN()
   total_params = sum(p.numel() for p in model.parameters())
   print(f"Nombre total de param√®tres : {total_params:,}")

**√Ä faire** :

1. Entra√Ænez ce mod√®le et comparez les performances
2. Exp√©rimentez avec diff√©rentes valeurs de dropout (0.3, 0.5, 0.7)

.. slide::

5.2. Data Augmentation
~~~~~~~~~~~~~~~~~~~

Ajoutez de l'augmentation de donn√©es pour am√©liorer la g√©n√©ralisation :

.. code-block:: python

   import torchvision.transforms as transforms

   # Transformations pour l'entra√Ænement (avec augmentation)
   train_transform = transforms.Compose([
       transforms.RandomHorizontalFlip(),
       transforms.RandomCrop(32, padding=4),
       transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
       transforms.ToTensor(),
       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
   ])

   # Transformations pour validation/test (sans augmentation)
   test_transform = transforms.Compose([
       transforms.ToTensor(),
       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
   ])

   # Charger les donn√©es avec les bonnes transformations
   trainset = torchvision.datasets.CIFAR10(
       root='./data',
       train=True,
       download=True,
       transform=train_transform
   )

   testset = torchvision.datasets.CIFAR10(
       root='./data',
       train=False,
       download=True,
       transform=test_transform
   )

**Questions** :

1. Quelle am√©lioration apporte l'augmentation de donn√©es ?
2. Pourquoi n'applique-t-on pas l'augmentation sur le test set ?

.. slide::

üìã Exercice 6 : Visualisation et analyse (üå∂Ô∏è)
----------------------

**Objectif** : Analyser les performances du mod√®le

6.1. Matrice de confusion
~~~~~~~~~~~~~~~~~~~

Cr√©ez un fichier ``tp5_analysis.py`` :

.. code-block:: python

   import torch
   import numpy as np
   import matplotlib.pyplot as plt
   from sklearn.metrics import confusion_matrix, classification_report
   import seaborn as sns

   def plot_confusion_matrix(model, dataloader, classes, device):
       """Affiche la matrice de confusion"""
       model.eval()
       all_preds = []
       all_labels = []
       
       with torch.no_grad():
           for images, labels in dataloader:
               images = images.to(device)
               outputs = model(images)
               _, predicted = torch.max(outputs, 1)
               
               all_preds.extend(predicted.cpu().numpy())
               all_labels.extend(labels.numpy())
       
       # Calculer la matrice de confusion
       cm = confusion_matrix(all_labels, all_preds)
       
       # Afficher
       plt.figure(figsize=(12, 10))
       sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=classes, yticklabels=classes)
       plt.title('Matrice de confusion')
       plt.ylabel('Vraie classe')
       plt.xlabel('Classe pr√©dite')
       plt.tight_layout()
       plt.savefig('confusion_matrix.png')
       plt.show()
       
       # Afficher le rapport de classification
       print("\nRapport de classification :")
       print(classification_report(all_labels, all_preds, target_names=classes))

   # Utilisation
   from tp5_dataset import testloader
   from tp5_cnn_advanced import ImprovedCNN
   from tp5_preparation import classes

   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
   model = ImprovedCNN().to(device)

   # Charger le meilleur mod√®le
   checkpoint = torch.load('best_cnn_cifar10.pth')
   model.load_state_dict(checkpoint['model_state_dict'])

   plot_confusion_matrix(model, testloader, classes, device)

.. slide::

6.2. Visualiser les pr√©dictions
~~~~~~~~~~~~~~~~~~~

Ajoutez une fonction pour visualiser les pr√©dictions :

.. code-block:: python

   import matplotlib.pyplot as plt
   import numpy as np
   import torchvision

   def visualize_predictions(model, dataloader, classes, device, num_images=20):
       """Visualise des pr√©dictions du mod√®le"""
       model.eval()
       
       # Obtenir un batch
       dataiter = iter(dataloader)
       images, labels = next(dataiter)
       images, labels = images.to(device), labels.to(device)
       
       # Faire les pr√©dictions
       with torch.no_grad():
           outputs = model(images)
           _, predicted = torch.max(outputs, 1)
       
       # Afficher les images avec leurs pr√©dictions
       fig, axes = plt.subplots(4, 5, figsize=(15, 12))
       
       for idx, ax in enumerate(axes.flat):
           if idx >= num_images:
               break
           
           # D√©normaliser l'image
           img = images[idx].cpu() / 2 + 0.5
           img = np.transpose(img.numpy(), (1, 2, 0))
           
           # Afficher
           ax.imshow(img)
           
           true_label = classes[labels[idx]]
           pred_label = classes[predicted[idx]]
           color = 'green' if labels[idx] == predicted[idx] else 'red'
           
           ax.set_title(f'Vrai: {true_label}\nPr√©d: {pred_label}', 
                       color=color, fontsize=10)
           ax.axis('off')
       
       plt.tight_layout()
       plt.savefig('predictions_visualization.png')
       plt.show()

   # Utilisation
   visualize_predictions(model, testloader, classes, device)

.. slide::

üìã Exercice 7 : Exp√©rimentations (üå∂Ô∏è)
----------------------

**Objectif** : Explorer diff√©rentes configurations

7.1. Comparaison de plusieurs mod√®les
~~~~~~~~~~~~~~~~~~~

Cr√©ez un fichier ``tp5_experiments.py`` pour comparer plusieurs configurations :

.. code-block:: python

   import torch
   import torch.nn as nn
   import torch.optim as optim
   from torch.utils.data import DataLoader
   import pandas as pd
   import matplotlib.pyplot as plt

   def train_and_evaluate(model, trainloader, valloader, testloader, 
                          device, num_epochs=20, lr=0.001, model_name="Model"):
       """Entra√Æne et √©value un mod√®le"""
       criterion = nn.CrossEntropyLoss()
       optimizer = optim.Adam(model.parameters(), lr=lr)
       
       history = {
           'train_loss': [],
           'train_acc': [],
           'val_acc': []
       }
       
       best_val_acc = 0.0
       
       for epoch in range(num_epochs):
           # Phase d'entra√Ænement
           model.train()
           train_loss = 0.0
           train_correct = 0
           train_total = 0
           
           for images, labels in trainloader:
               images, labels = images.to(device), labels.to(device)
               
               outputs = model(images)
               loss = criterion(outputs, labels)
               
               optimizer.zero_grad()
               loss.backward()
               optimizer.step()
               
               train_loss += loss.item()
               _, predicted = torch.max(outputs, 1)
               train_total += labels.size(0)
               train_correct += (predicted == labels).sum().item()
           
           train_acc = 100 * train_correct / train_total
           
           # Phase de validation
           model.eval()
           val_correct = 0
           val_total = 0
           
           with torch.no_grad():
               for images, labels in valloader:
                   images, labels = images.to(device), labels.to(device)
                   outputs = model(images)
                   _, predicted = torch.max(outputs, 1)
                   val_total += labels.size(0)
                   val_correct += (predicted == labels).sum().item()
           
           val_acc = 100 * val_correct / val_total
           
           # Enregistrer l'historique
           history['train_loss'].append(train_loss / len(trainloader))
           history['train_acc'].append(train_acc)
           history['val_acc'].append(val_acc)
           
           # Sauvegarder le meilleur
           if val_acc > best_val_acc:
               best_val_acc = val_acc
               torch.save(model.state_dict(), f'{model_name}_best.pth')
           
           if (epoch + 1) % 5 == 0:
               print(f"[{model_name}] Epoch [{epoch+1}/{num_epochs}], "
                     f"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%")
       
       # Test final
       model.load_state_dict(torch.load(f'{model_name}_best.pth'))
       model.eval()
       test_correct = 0
       test_total = 0
       
       with torch.no_grad():
           for images, labels in testloader:
               images, labels = images.to(device), labels.to(device)
               outputs = model(images)
               _, predicted = torch.max(outputs, 1)
               test_total += labels.size(0)
               test_correct += (predicted == labels).sum().item()
       
       test_acc = 100 * test_correct / test_total
       
       return history, test_acc

**√Ä faire** :

Comparez les architectures suivantes :

1. MLP simple
2. CNN simple (3 couches conv)
3. CNN avec Batch Normalization
4. CNN plus profond (5-6 couches conv)

Pour chaque mod√®le, tracez l'√©volution de la loss et de l'accuracy.

.. slide::

7.2. Tracer les courbes d'apprentissage
~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   def plot_training_curves(histories, model_names):
       """Trace les courbes d'apprentissage pour plusieurs mod√®les"""
       fig, axes = plt.subplots(1, 3, figsize=(18, 5))
       
       for history, name in zip(histories, model_names):
           epochs = range(1, len(history['train_loss']) + 1)
           
           # Loss
           axes[0].plot(epochs, history['train_loss'], label=name)
           
           # Train accuracy
           axes[1].plot(epochs, history['train_acc'], label=name)
           
           # Val accuracy
           axes[2].plot(epochs, history['val_acc'], label=name)
       
       axes[0].set_title('Loss d\'entra√Ænement')
       axes[0].set_xlabel('Epoch')
       axes[0].set_ylabel('Loss')
       axes[0].legend()
       axes[0].grid(True)
       
       axes[1].set_title('Pr√©cision d\'entra√Ænement')
       axes[1].set_xlabel('Epoch')
       axes[1].set_ylabel('Accuracy (%)')
       axes[1].legend()
       axes[1].grid(True)
       
       axes[2].set_title('Pr√©cision de validation')
       axes[2].set_xlabel('Epoch')
       axes[2].set_ylabel('Accuracy (%)')
       axes[2].legend()
       axes[2].grid(True)
       
       plt.tight_layout()
       plt.savefig('training_curves_comparison.png')
       plt.show()

.. slide::

üìã Exercice Bonus : Transfer Learning (üå∂Ô∏èüå∂Ô∏è)
----------------------

**Objectif** : Utiliser un mod√®le pr√©-entra√Æn√©

8.1. Charger un mod√®le pr√©-entra√Æn√©
~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   import torchvision.models as models
   import torch.nn as nn

   # Charger ResNet18 pr√©-entra√Æn√© sur ImageNet
   model = models.resnet18(pretrained=True)

   # Geler les poids des couches convolutives
   for param in model.parameters():
       param.requires_grad = False

   # Remplacer la derni√®re couche pour CIFAR-10 (10 classes)
   num_features = model.fc.in_features
   model.fc = nn.Linear(num_features, 10)

   # Seule la derni√®re couche sera entra√Æn√©e
   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
   model = model.to(device)

   # Optimiseur uniquement pour la derni√®re couche
   optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)

**√Ä faire** :

1. Entra√Ænez ce mod√®le et comparez avec vos CNN from scratch
2. Exp√©rimentez avec le fine-tuning : d√©gelez les derni√®res couches convolutives

.. slide::

üìä R√©capitulatif et questions
----------------------

**R√©sum√© des concepts cl√©s** :

- MLP vs CNN : r√©duction drastique des param√®tres
- Convolutions : partage de poids et structure spatiale
- Pooling : r√©duction de dimensionnalit√©
- Mini-batchs : compromis efficacit√©/stabilit√©
- Dataset/DataLoader : gestion automatique des donn√©es
- Sauvegarde : state_dict pour la flexibilit√©

**Questions de r√©flexion** :

1. Pourquoi les CNN performent-ils mieux que les MLP sur les images ?
2. Quel est le r√¥le du pooling dans un CNN ?
3. Comment choisir la taille des mini-batchs ?
4. Pourquoi s√©pare-t-on train/validation/test ?
5. Quand utiliser le transfer learning ?

**Pour aller plus loin** :

- Essayez d'autres architectures : VGG, ResNet, DenseNet
- Impl√©mentez des techniques d'augmentation avanc√©es
- Utilisez un scheduler pour le learning rate
- Explorez la visualisation des filtres convolutifs
- Testez sur d'autres datasets : CIFAR-100, STL-10

.. note::

   üí° **Conseil** : Gardez trace de toutes vos exp√©riences dans un tableur ou un notebook. Notez les hyperparam√®tres, les r√©sultats et vos observations. C'est une pratique essentielle en deep learning !
