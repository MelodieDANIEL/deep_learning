
.. slide::

Chapitre 1 - Introduction Ã  PyTorch et Optimisation de ModÃ¨les (partie 2)
================

ğŸ¯ Objectifs du Chapitre
----------------------

.. important::

   Ã€ la fin de ce chapitre, vous saurez : 

   - CrÃ©er et manipuler des tenseurs PyTorch sur CPU et GPU.
   - Calculer automatiquement les gradients Ã  lâ€™aide de ``autograd``.
   - DÃ©finir une fonction de perte.
   - Utiliser un optimiseur pour ajuster les paramÃ¨tres dâ€™un modÃ¨le.
   - ImplÃ©menter une boucle d'entraÃ®nement simple.

.. slide::
ğŸ“– 13. Les fonctions de perte (Loss Functions)
-------------------------------

Lorsquâ€™on entraÃ®ne un rÃ©seau de neurones, lâ€™objectif est de minimiser lâ€™erreur entre les prÃ©dictions du modÃ¨le et les valeurs attendues. Cette erreur est mesurÃ©e par une fonction de perte (loss function en anglais).

Une fonction de perte prend en entrÃ©e :

    - la sortie du modÃ¨le (la prÃ©diction),
    - la valeur cible (la rÃ©ponse attendue, donnÃ©e par les donnÃ©es dâ€™apprentissage),

et retourne un nombre rÃ©el qui indique "Ã  quel point le modÃ¨le s'est trompÃ©".

Par consÃ©quent, plus la perte est grande â†’ plus le modÃ¨le se trompe et plus la perte est petite â†’ plus le modÃ¨le est proche de la bonne rÃ©ponse.

.. slide::
ğŸ“– 14. Pourquoi la fonction de perte est essentielle ?
----------------------------------------------------
La fonction de perte est essentielle pour plusieurs raisons :

    - Elle quantifie l'erreur du modÃ¨le : elle donne une mesure numÃ©rique de la performance du modÃ¨le.
    - Elle permet de guider l'apprentissage : le modÃ¨le apprend en essayant de rÃ©duire cette valeur.
    - Elle est le point de dÃ©part de la rÃ©tropropagation : les gradients sont calculÃ©s Ã  partir de la fonction de perte.
    - Elle est utilisÃ©e par les algorithmes d'optimisation pour ajuster les paramÃ¨tres du modÃ¨le.
    - Elle permet de comparer diffÃ©rents modÃ¨les : en utilisant la mÃªme fonction de perte, on peut Ã©valuer quel modÃ¨le est le meilleur.
    - Elle est essentielle pour le processus d'entraÃ®nement : sans fonction de perte, le modÃ¨le n'aurait aucun signal pour savoir comment sâ€™amÃ©liorer.

.. slide::
ğŸ“– 15. RÃ©gression & Erreur quadratique moyenne (MSE)
----------------------------------------------------

15.1. DÃ©finitions
~~~~~~~~~~~~~~~~~
On appelle rÃ©gression le cas oÃ¹ le modÃ¨le doit prÃ©dire une valeur numÃ©rique par exemple : la tempÃ©rature demain, la taille dâ€™une personne, etc.

Dans ce cas, la fonction de perte la plus utilisÃ©e est lâ€™erreur quadratique moyenne (MSE de l'anglais Mean Squared Error) :

.. math::

   L(y, \hat{y}) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2,

oÃ¹ :

    - $$L$$ est la fonction de perte,
    - $$n$$ est le nombre de donnÃ©es,
    - $$y_i$$ est la valeur attendue (target) et
    - $$\hat{y}_i$$ est la prÃ©diction du modÃ¨le.

La fonction MSE calcule la moyenne des erreurs au carrÃ© de toutes les donnÃ©es.

.. slide::
15.2. Exemple d'une rÃ©gression avec MSE dans PyTorch
~~~~~~~~~~~~~~~~~~~~~
Pour utiliser la fonction MSE dans PyTorch, on peut utiliser la classe ``nn.MSELoss()``. Pour cela, il faut d'abord importer le module ``torch.nn`` qui contient les fonctions de perte :
.. code-block:: python

    import torch.nn as nn

**Exemple** : 

.. code-block:: python

    # Valeurs rÃ©elles et prÃ©dictions
    y_true = torch.tensor([2.0, 3.0, 4.0])
    y_pred = torch.tensor([2.5, 2.7, 4.2])

    # DÃ©finition de la fonction de perte MSE
    loss_fn = nn.MSELoss()

    # Calcul de la perte
    loss = loss_fn(y_pred, y_true)
    print(loss)

.. slide::
ğŸ“– 16. Classification & Entropie croisÃ©e
------------------------------------------------------------

16.1. DÃ©finitions
~~~~~~~~~~~~~~~~~~~

On appelle classification le cas oÃ¹ le modÃ¨le doit prÃ©dire Ã  quelle catÃ©gorie appartient la donnÃ©e parmi plusieurs possibles par exemple : "chat" ou "chien", ou bien "spam" ou "non spam", etc.

Dans ce cas, la fonction de perte la plus courante est l'entropie croisÃ©e (Cross-Entropy Loss en anglais). Elle compare la probabilitÃ© prÃ©dite par le modÃ¨le et la vraie catÃ©gorie (donnÃ©e par les donnÃ©es dâ€™apprentissage) :

.. math::
   L(y, \hat{y}) = -\sum_{i=1}^n y_i \log(\hat{y}_i),
oÃ¹ :

    - $$L$$ est la fonction de perte,
    - $$n$$ est le nombre de classes,
    - $$y_i$$ est la valeur attendue (target) pour la classe $$i$$ ((souvent codÃ©e en *one-hot encoding*, c'est-Ã -dire un vecteur avec un 1 pour la bonne classe et 0 pour les autres),
    - $$\hat{y}_i$$ est la probabilitÃ© prÃ©dite par le modÃ¨le pour la classe $$i$$.

La fonction enropie croisÃ©e mesure la distance entre la distribution de probabilitÃ© prÃ©dite par le modÃ¨le et la distribution de probabilitÃ© rÃ©elle (la vraie classe).
La prÃ©sence de la somme permet de prendre en compte toutes les classes.   Mais, dans le cas du *one-hot encoding*, seul le terme correspondant Ã  la vraie classe reste (puisque tous les autres $$y_i$$ valent 0).

.. slide::
16.2. Pourquoi l'entropie croisÃ©e ?
~~~~~~~~~~~~~~~~~~~
L'entropie croisÃ©e est utilisÃ©e car :

    - Elle est adaptÃ©e aux problÃ¨mes de classification multi-classes.
    - Elle pÃ©nalise fortement les erreurs de classification, surtout lorsque la probabilitÃ© prÃ©dite pour la classe correcte est faible.
    - Elle est diffÃ©rentiable, ce qui permet de l'utiliser avec les algorithmes d'optimisation basÃ©s sur la rÃ©tropropagation.

.. slide::
16.3. Exemple d'une classification avec Cross-Entropy Loss 
~~~~~~~~~~~~~~~~~~~~
Prenons un exemple oÃ¹ on a 3 classes possibles : "Chat", "Chien", "Oiseau". Nous avons : 

- La sortie du modÃ¨le suivante : $$\hat{y} = [0.7, 0.2, 0.1]$$ et
- imaginons que la vraie classe est "Chat", donc $$y = [1, 0, 0]$$.

Alors :

.. math::

    L = - \big( 1 \cdot \log(0.7) + 0 \cdot \log(0.2) + 0 \cdot \log(0.1) \big)

Les termes multipliÃ©s par 0 disparaissent :

.. math::

    L = -\log(0.7)

ğŸ‘‰ La perte est faible car le modÃ¨le a donnÃ© une forte probabilitÃ© Ã  la bonne classe.

Si au contraire le modÃ¨le avait prÃ©dit : $$\hat{y} = [0.2, 0.7, 0.1]$$ :

.. math::

    L = -\log(0.2)

ğŸ‘‰ La perte serait plus grande, car la probabilitÃ© attribuÃ©e Ã  la bonne classe ("Chat") est faible.


.. slide::
16.4. Le mÃªme exemple dans PyTorch 
~~~~~~~~~~~~~~~~~~~~

Pour utiliser la fonction Cross-Entropy Loss dans PyTorch, on peut utiliser la classe ``nn.CrossEntropyLoss()`` du module ``torch.nn``.

.. code-block:: python

    # DÃ©finition de la fonction de perte
    loss_fn = nn.CrossEntropyLoss()

    # Cas 1 : le modÃ¨le prÃ©dit correctement (forte valeur pour "Chat")
    logits1 = torch.tensor([[2.0, 1.0, 0.1]])  # sortie brute du modÃ¨le qui sera convertie Ã  l'aide d'une fonction de PyTorch en probabilitÃ©s
    y_true = torch.tensor([0])  # la vraie classe est "Chat" (indice 0)

    loss1 = loss_fn(logits1, y_true)
    print("Perte (bonne prÃ©diction) :", loss1.item())

    # Cas 2 : le modÃ¨le se trompe (forte valeur pour "Chien")
    logits2 = torch.tensor([[0.2, 2.0, 0.1]])  # sortie brute du modÃ¨le qui sera convertie Ã  l'aide d'une fonction de PyTorch en probabilitÃ©s
    loss2 = loss_fn(logits2, y_true)
    print("Perte (mauvaise prÃ©diction) :", loss2.item())

.. slide::
ğŸ“– 17. Optimisation
-----------------------

Lâ€™optimisation est lâ€™Ã©tape qui permet dâ€™ajuster les paramÃ¨tres du modÃ¨le pour quâ€™il rÃ©alise mieux la tÃ¢che demandÃ©e.  

Lâ€™idÃ©e est simple :  

1. On calcule la perte (loss en anglais) qui indique lâ€™erreur du modÃ¨le.  
2. On calcule le gradient de la perte par rapport aux paramÃ¨tres (grÃ¢ce Ã  Autograd).  
3. On met Ã  jour les paramÃ¨tres dans la bonne direction (celle qui diminue la perte).  

Câ€™est un processus itÃ©ratif qui se rÃ©pÃ¨te jusquâ€™Ã  ce que le modÃ¨le apprenne correctement.


.. slide::
ğŸ“– 18. Descente de gradient
-----------------------

Lâ€™algorithme dâ€™optimisation le plus courant est la descente de gradient (ou Gradient Descent en anglais). 

18.1. Principe et formule de la descente de gradient
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Imaginons une montagne :  
- La hauteur correspond Ã  la valeur de la fonction de perte.  
- Le but est de descendre la montagne pour atteindre la vallÃ©e (la perte minimale).  
- Le gradient indique la pente : on suit la pente descendante pour rÃ©duire la perte.

Formule de mise Ã  jour des paramÃ¨tres :

.. math::

   \theta_{new} = \theta_{old} - \eta \cdot \nabla_\theta L(\theta)

oÃ¹ :  

- $$\theta$$ reprÃ©sente lâ€™ensemble des paramÃ¨tres du modÃ¨le,  
- $$L$$ est la fonction de perte,  
- $$\eta$$ est le taux dâ€™apprentissage (*learning rate* en anglais) : il contrÃ´le la taille des pas et  
- $$\nabla_\theta L(\theta)$$ dÃ©signe le vecteur des dÃ©rivÃ©es partielles de $$L$$ par rapport Ã  chacun des paramÃ¨tres.  


.. slide::
ğŸ“– 18.2. Exemple simple de la descente de gradient
~~~~~~~~~~~~~~~~~~~~~~~~
Prenons un exemple trÃ¨s simple : nous voulons ajuster un seul paramÃ¨tre $$a$$ pour approximer une fonction.

Supposons que le modÃ¨le soit une droite passant par lâ€™origine :

.. math::

   f(x) = a x

Nous avons une donnÃ©e dâ€™apprentissage :  

- EntrÃ©e : $$x = 2$$  
- Sortie attendue : $$y = 4$$  

On part du paramÃ¨tre initial : $$a = 0$$.

.. slide::
**1. Fonction de perte**

On utilise lâ€™erreur quadratique (MSE) pour mesurer lâ€™Ã©cart entre la prÃ©diction et la vraie valeur :

.. math::

   L(a) = (f(x) - y)^2 = (a * 2 - 4)^2


**2. Calcul du gradient**

On dÃ©rive la perte par rapport Ã  $$a$$ :

.. math::

   \frac{\partial L}{\partial a} = 2 * (a * 2 - 4) * 2 = 8a - 16

.. slide::

**3. Mise Ã  jour avec descente de gradient**

On choisit un taux dâ€™apprentissage $$\eta = 0.1$$ et on applique la formule :

.. math::

   a_{new} = a_{old} - \eta \cdot \frac{\partial L}{\partial a}


**4. Exemple numÃ©rique**

- Point de dÃ©part : $$a = 0$$  
- Gradient : $$\frac{\partial L}{\partial a} = 8 * 0 - 16 = -16$$  
- Mise Ã  jour :  

.. math::

   a_{new} = 0 - 0.1 * (-16) = 1.6

ğŸ‘‰ AprÃ¨s une Ã©tape, $$a$$ se rapproche dÃ©jÃ  de la bonne valeur (qui devrait Ãªtre $$a = 2$$ pour que $$f(x) = 2 * 2 = 4$$).  

En rÃ©pÃ©tant plusieurs mises Ã  jour, $$a$$ converge vers 2, et la perte devient de plus en plus faible.


.. slide::
ğŸ“– 19. Descente de gradient avec PyTorch
----------------------------------------

PyTorch fournit le module ``torch.optim`` qui implÃ©mente plusieurs algorithmes dâ€™optimisation. Dans PyTorch, lâ€™algorithme de descente de gradient est appelÃ© SGD (Stochastic Gradient Descent) et peut Ãªtre importÃ© via ``torch.optim.SGD`` :

.. code-block:: python
   import torch.optim as optim

On reprend le modÃ¨le simple :

- ModÃ¨le : $$f(x) = ax$$
- Objectif : trouver $$a$$ tel que $$f(x) â‰ˆ y$$
- Jeu de donnÃ©es : $$x = [1, 2, 3, 4], y = [2, 4, 6, 8]$$
- ParamÃ¨tre initial : $$a = 0$$
- Taux d'apprentissage : $$\eta = lr = 0.1$$

.. slide::
.. code-block:: python
    # DonnÃ©es
    x = torch.tensor([1.0, 2.0, 3.0, 4.0])
    y = torch.tensor([2.0, 4.0, 6.0, 8.0])
    a = torch.tensor([0.0], requires_grad=True)

    # Optimiseur : descente de gradient
    optimizer = optim.SGD([a], lr=0.1)

    # Fonction de perte : MSE
    loss_fn = nn.MSELoss()

    for i in range(10):
        # 1. Remettre les gradients Ã  zÃ©ro avant de recalculer
        optimizer.zero_grad()
        
        # 2. Calcul de la prÃ©diction
        y_pred = a * x
        
        # 3. Calcul de la perte avec MSE
        loss = loss_fn(y_pred, y)
        
        # 4. Calcul automatique des gradients
        loss.backward()
        
        # 5. Mise Ã  jour du paramÃ¨tre a
        optimizer.step()
        
        print(f"Iter {i+1}: a = {a.item()}, loss = {loss.item()}")

.. note::

      Explications des nouvelles lignes de code :

         - ``optimizer.zero_grad()`` : remet Ã  zÃ©ro les gradients calculÃ©s lors de la derniÃ¨re itÃ©ration.  
         Sinon, PyTorch additionne les gradients Ã  chaque ``backward()``, ce qui fausserait les calculs.
         
         - ``optimizer.step()`` : applique la mise Ã  jour des paramÃ¨tres selon la rÃ¨gle de la descente de gradient :  
         $$a_{new} = a_{old} - lr * \frac{\partial loss}{\partial a}$$.
         

Dans cet exemple, SGD converge trÃ¨s vite car le problÃ¨me est simple.
 
.. slide::
ğŸ“– 20. Optimiseur Adam
--------------------------------------

20.1. DÃ©finition
~~~~~~~~~~~~~~~~~~
Adam est un autre algorithme d'optimisation qui adapte le pas pour chaque paramÃ¨tre grÃ¢ce Ã  une moyenne mobile des gradients ($$m_t$$ ) et une moyenne mobile des carrÃ©s des gradients ($$v_t$$).  

On dÃ©finit :

- $$g_t = \nabla_\theta L(\theta)$$ : le gradient Ã  l'itÃ©ration t  
- $$m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t$$ : moyenne mobile des gradients (1er moment)  
- $$v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2$$ : moyenne mobile des carrÃ©s des gradients (2e moment)  
- $$\hat{m}_t = \frac{m_t}{1-\beta_1^t}$$ : correction de biais pour le 1er moment  
- $$\hat{v}_t = \frac{v_t}{1-\beta_2^t}$$ : correction de biais pour le 2e moment  
- $$\epsilon$$ : petite constante pour Ã©viter la division par zÃ©ro  

La mise Ã  jour des paramÃ¨tres est alors :

.. math::
  \theta_{\text{new}} = \theta_{\text{old}} - \eta \cdot \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}

ğŸ’¡ InterprÃ©tation :

- $$m_t$$ capture la direction moyenne des gradients (ce qui Ã©vite les oscillations),  
- $$v_t$$ ajuste le pas selon la variance des gradients (pour qu'il ne soitpas plus grand si le gradient est bruitÃ©),  
- $$\epsilon$$ empÃªche la division par zÃ©ro et
- la correction de biais $$\hat{m}_t, \hat{v}_t$$ est importante surtout au dÃ©but pour ne pas sous-estimer les moments.

.. slide::
20.2. Adam vs. SGD
~~~~~~~~~~~~~~~~~~~~~
 DiffÃ©rences entre Adam et la descente de gradient classique (SGD) :

    1. **SGD** applique la mÃªme rÃ¨gle de mise Ã  jour pour tous les paramÃ¨tres Ã  chaque itÃ©ration :  
       $$\theta_{new} = \theta_{old} - lr * \frac{\partial L}{\partial \theta}$$.
       
    2. **Adam** adapte le taux d'apprentissage pour chaque paramÃ¨tre individuellement,  
       en utilisant des moyennes mobiles des gradients et des carrÃ©s des gradients.  
       Cela permet souvent une convergence plus rapide et plus stable.
    
    3. La syntaxe PyTorch reste trÃ¨s similaire : on utilise toujours ``optimizer.zero_grad()``, ``loss.backward()`` et ``optimizer.step()``. On peut reprendre le mÃªme modÃ¨le simple que prÃ©cÃ©demment Ã  titre d'exemple.

.. note::
   âš ï¸ Remarque : Dans le cadre de ce cours, nous utiliserons principalement Adam pour sa robustesse et sa facilitÃ© d'utilisation. Nous allons surtout utiliser l'implÃ©mentation de ADAM dans Pytorch sans avoir Ã  recoder les Ã©quations. Elles sont Ã©noncÃ©es Ã  titre informatif.

.. slide::
20.3. ImplÃ©mentation d'Adam avec PyTorch
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Dans PyTorch, Adam est implÃ©mentÃ© via ``torch.optim.Adam`` :

.. code-block:: python
    # DonnÃ©es
    x = torch.tensor([1.0, 2.0, 3.0, 4.0])
    y = torch.tensor([2.0, 4.0, 6.0, 8.0])
    a = torch.tensor([0.0], requires_grad=True)

    # Optimiseur : Adam
    optimizer = torch.optim.Adam([a], lr=0.1)

    # Fonction de perte : MSE
    loss_fn = nn.MSELoss()

    for i in range(50):
        optimizer.zero_grad()  # remise Ã  zÃ©ro des gradients
        y_pred = a * x
        loss = loss_fn(y_pred, y)  # perte MSE
        loss.backward()  # calcul automatique des gradients
        optimizer.step()  # mise Ã  jour du paramÃ¨tre
        
        print(f"Iter {i+1}: a = {a.item()}, loss = {loss.item()}")

ğŸ’¡ Remarques :

   - Pour des problÃ¨mes **simples** comme $$f(x)=ax$$, SGD converge trÃ¨s vite et Adam peut sembler plus lent sur peu dâ€™itÃ©rations.  
   - Pour des **modÃ¨les complexes** avec beaucoup de paramÃ¨tres et des gradients bruitÃ©s, Adam est souvent plus efficace grÃ¢ce Ã  ses ajustements adaptatifs.


.. slide::
âš–ï¸ Exercice 2 : Trouver la droite qui passe au mieux par les donnÃ©es avec MSE
------------------------------------

Dans cet exercice, vous allez implÃ©menter une **boucle d'entraÃ®nement simple** pour ajuster les paramÃ¨tres d'une droite aux donnÃ©es fournies.

On vous donne les donnÃ©es suivantes :

.. code-block:: python

    # DonnÃ©es bruitÃ©es suivantes
    import numpy as np
    x = np.random.rand(1000)
    y_true = x * 1.54 + 12.5 + np.random.rand(1000)*0.2
    

**Objectif :** Trouver une droite de la forme :

.. math::

    y = f(x) =a x + b

oÃ¹ : $$a$$ et $$b$$ sont des paramÃ¨tres appris automatiquement en minimisant l'erreur entre les prÃ©dictions du modÃ¨le et les donnÃ©es rÃ©elles.

**Consigne :** Ã‰crire un programme qui ajuste les paramÃ¨tres $$a$$ et $$b$$ de la droite aux donnÃ©es fournies en utilisant  PyTorch.

.. step::
    1) Dans un premier temps, vous pouvez faire une boucle de 10000 itÃ©rations et coder vous-mÃªme la fonction de perte.

.. step::
    2) Affichez les paramÃ¨tres appris $$a$$ et $$b$$.

.. step::
    3) Ensuite, trouvez un moyen plus intelligent d'arrÃªter l'entraÃ®nement de telle sorte que le modÃ¨le converge avec le minimum d'itÃ©rations.

.. step::
    4) Affichez le nombre d'itÃ©rations nÃ©cessaires pour converger.

.. step::
    5) Tracez les donnÃ©es rÃ©elles et les donnÃ©es prÃ©dites pour comparer visuellement le rÃ©sultat.

.. step::
    6) Utilisez la fonction de perte MSE fournie par PyTorch et affichez les paramÃ¨tres appris $$a$$ et $$b$$.

.. step::
    7) VÃ©rifiez que le rÃ©sultat des paramÃ¨tres et le tracÃ© sont similaires Ã  ceux obtenus avec la boucle d'entraÃ®nement manuelle.


**Remarque :** Pour utiliser ``matplotlib``, vous devez l'installer avec la commande suivante :

.. code-block:: bash
    pip install matplotlib

Puis, vous pouvez l'importer dans votre code avec :

.. code-block:: python
    import matplotlib.pyplot as plt
    %matplotlib inline #Ã€ ajouter si vous utilisez Jupyter Notebook


**Astuce :**
.. spoiler::
    .. discoverList::
        1. CrÃ©er les paramÃ¨tres : $$a$$ et $$b$$ sous forme de tenseurs dÃ©rivables.
        2. Initialiser les paramÃ¨tres : $$a$$ et $$b$$ Ã  zÃ©ro.
        3. CrÃ©er un optimiseur Adam (``torch.optim.Adam``) avec un taux d'apprentissage (learning rate) de 1e-3.
        4. Utiliser une fonction de perte en codant l'Ã©quation de la MSE (``torch.mean((y_true - y_pred) ** 2)`` ou ``loss = torch.sum((y_pred - y_true) ** 2) / y_true.shape[0]``).
        5. ImplÃ©menter une boucle d'entraÃ®nement (par exemple 100000 itÃ©rations) avec l'optimiseur ADAM.
        6. Ã€ chaque itÃ©ration :
            - calculer les prÃ©dictions,
            - calculer la perte,
            - effectuer la rÃ©tropropagation,
            - mettre Ã  jour les paramÃ¨tres : $$a$$ et $$b$$.

        7. Il faut arrÃªter l'entraÃ®nement lorsque la perte est suffisamment faible (par exemple, infÃ©rieure Ã  0.01)

**RÃ©sultat attendu :** Vous devez obtenir un graphique oÃ¹ :  
    - les points bleus correspondent aux donnÃ©es rÃ©elles (``y_true``),  
    - et une droite rouge correspond aux prÃ©dictions (``y_pred``).  

Exemple dâ€™affichage attendu :

.. image:: images/chap1_exo_2_resultat.png
    :alt: droite ajustÃ©e aux points
    :align: center


.. slide::
âš–ï¸ Exercice 3 : Trouver la droite qui passe au mieux par les donnÃ©es avec une fonction de perte de type valeur absolue
--------------------------------------------------

**Objectif** :  
L'objectif est le mÃªme que celui de l'exercice prÃ©cÃ©dent (faire de la rÃ©gression linÃ©aire), mais cette fois-ci,  vous allez utiliser une fonction de perte de type valeur absolue (MAE de l'anglais Mean Absolute Error)  au lieu de la MSE. Lâ€™idÃ©e de cet exercice est de comparer deux optimisateurs SGD et Adam.

**Consignes :**  ImplÃ©menter une boucle d'entraÃ®nement pour ajuster les paramÃ¨tres d'une droite aux donnÃ©es fournies dans l'exercice prÃ©cÃ©dent en utilisant une fonction de perte de type valeur absolue et en rÃ©utilisant l'implÃ©mentation de l'exercice prÃ©cÃ©dent.

.. step:: 
 
    1) RÃ©utilisez la boucle d'entraÃ®nement de lâ€™exercice prÃ©cÃ©dent qui s'arrÃªte au bout de 2500 itÃ©rations et qui utilise un learning rate de 0.01.  

.. step:: 
    2) Remplacez la fonction de perte MSE par une fonction de perte de type MAE. Il faudra chercher dans la documentation comment l'implÃ©menter dans PyTorch.  
   
.. step::    
    3) Testez avec lâ€™optimiseur SGD puis avec lâ€™optimiseur Adam.  

.. step:: 
    4) Pour chaque optimiseur, affichez les paramÃ¨tres appris $$a$$ et $$b$$.

.. step::
    5) Tracez les donnÃ©es rÃ©elles et les donnÃ©es prÃ©dites pour comparer visuellement les rÃ©sultats.  

.. step::
    6) Comparez les deux mÃ©thodes : que constatez-vous en termes de stabilitÃ© et de vitesse de convergence ?  

.. step::
    7) Expliquez quel optimiseur est meilleur et pourquoi?

.. step::
    8) Essayez de modifier le taux d'apprentissage (learning rate) pour voir son impact sur la convergence ainsi que le nombre d'itÃ©rations nÃ©cessaires.

**Astuce :**
.. spoiler::
    .. discoverList::
        - La valeur absolue dans PyTorch s'obtient avec la fonction ``nn.L1Loss()``.
        - Adam gÃ¨re mieux ce type de fonction de perte non dÃ©rivable partout.


**RÃ©sultat attendu :**
Vous devez obtenir des valeurs pour les paramÃ¨tres proches de :

    - Adam -> a = 1.5451, b = 12.5996
    - SGD  -> a = 2.3039, b = 12.1880


et un graphique similaire Ã  celui ci-dessous :

.. image:: images/chap1_exo_3_resultat.png
    :alt: droite ajustÃ©e aux points
    :align: center



.. slide::
ğŸ‹ï¸ Exercices SupplÃ©mentaires
--------------------

.. toctree::

    exos_sup_chap1