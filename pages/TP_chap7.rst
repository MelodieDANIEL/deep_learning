üèãÔ∏è Travaux Pratiques 7
=========================

Dans les exercices qui suivent, vous allez entra√Æner un mod√®le de classification sur un jeu de donn√©es d'images de v√™tements bien connu : FashionMNIST. Ce jeu de donn√©es contient 60 000 images d'entra√Ænement et 10 000 images de test, chacune repr√©sentant un v√™tement appartenant √† l'une des 10 cat√©gories suivantes.

.. warning::
    ‚ö†Ô∏è Ces exercices n√©cessitent un temps d'entra√Ænement cons√©quent. 
    Il est important de d√©velopper une bonne pratique de base de Data Scientist en IA : lorsqu'un entra√Ænement est en cours sur une version du code V, vous **devez** commencer √† programmer la version suivante V+1. 

    Cependant, une fois l'entra√Ænement V termin√©, il faut revenir dessus pour l'analyser et potentiellement effectuer des modifications avant de lancer V+1, ou planifier des modifications pour V+2.

    Le d√©veloppement de mod√®les d'IA est un processus it√©ratif exp√©rimental qui n√©cessite de la rigueur et de l'organisation.

Exercice 1 : Chargement du jeu de donn√©es
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Le jeu de donn√©es FashionMNIST est disponible directement via la biblioth√®que ``torchvision`` dans ``torchvision.datasets.FashionMNIST`` dont voici la documentation_.

.. _documentation: https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html

.. step::
    1) T√©l√©chargez les jeux ``train`` et ``validation`` en appelant 2 fois cette classe avec les bons arguments. Utilisez les transformations n√©cessaires pour convertir les images en tenseurs de dimensions $$H \times W = 28 \times 28$$.

.. note:: 
    üß† **Rappel:** Les transformations au chargement de jeux de donn√©es ont √©t√© vu au Chapitre 5, voir ``torchvision.transforms``.

.. step::
    2) Affichez la liste des classes du jeu de donn√©es. Quel est le format des labels (entiers, one-hot, etc.) ?

.. step::
    3) Pour chaque classe, affichez une image. Quelles sont les dimensions $$H \times W \times C$$ de chaque image ? 


Exercice 2 : D√©finition d'une architecture de r√©seau de neurones
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. step::
    1) Cr√©ez une architecture de r√©seau de neurone correspondant √† LeNet-5:

- C1: Convolution 6 filtres 5x5, stride 1, padding 0, activation ReLU
- Pooling 2x2, kernel 2, stride 2
- C2: Convolution 16 filtres 5x5, stride 1, padding 0, activation ReLU
- Pooling 2x2, kernel 2, stride 2
- Flatten
- F3: Fully connected 120 neurones, activation ReLU
- F4: Fully connected 84 neurones, activation ReLU
- F5: Fully connected 10 neurones (une par classe)

.. warning::
    ‚ö†Ô∏è Quelle activation devez-vous mettre en sortie de r√©seau ? Pourquoi ?

.. step::
    2) Quel est le nombre de param√®tres entra√Ænable dans cette architecture ? (Indice : utilisez ``model.parameters()`` et ``numel()``)

Exercice 3 : Lancer l'entra√Ænement 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. step::
    1) Chargez vos jeux de donn√©es en batchs avec ``torch.utils.data.DataLoader``.

.. step::
    2) Initialisez votre fonction de co√ªt ``torch.nn.CrossEntropyLoss()`` et votre optimiseur ``torch.optim.SGD()`` avec $$momentum=0.9$$ et $$learning\_rate=0.1$$).

.. step::
    3) Impl√©mentez une boucle d'entra√Ænement classique avec :

- une phase d'entra√Ænement
- une phase de validation
- affichage de la loss et de l'accuracy √† chaque √©poque pour les deux phases.
- affichage de la courbe de loss et val_loss en fonction des √©poques.

.. step::
    4) Lancez l'entra√Ænement pour 100 √©poques et notez les r√©sultats.

.. warning::

    Si l'entra√Ænement est trop long, utilisez un sous-ensemble du jeu de donn√©es.
    
    .. spoiler::
        .. discoverList::
            .. code-block:: python
                
                trainset_target_size = 10000
                valset_target_size = 2000
                
                trainset = datasets.FashionMNIST(...)
                trainset.data = trainset.data[:trainset_target_size]
                trainset.targets = trainset.targets[:trainset_target_size]

                valset = datasets.FashionMNIST(...)
                valset.data = valset.data[:valset_target_size]
                valset.targets = valset.targets[:valset_target_size]

Exercice 4 : Early Stopping
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. step::
    1) Impl√©mentez une strat√©gie d'Early Stopping qui arr√™te l'entra√Ænement si la validation loss ne s'est pas am√©lior√©e d'au moins 0.005 pendant 5 √©poques cons√©cutives.

.. step::
    2) Comparez le nombre d'√©poques effectu√©es avec et sans Early Stopping. Quel est l'impact sur les performances du mod√®le ?

Exercice 5 : R√©gularisation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Pour cet exercice, vous pouvez afficher les valeurs des param√®tres de votre mod√®le (ou quelques valeurs descriptives telles que min, max, mean et std).
.. spoiler::
    .. discoverList::
        .. code-block:: python
            model = YourModel(...)

            param_stats = {
                "min": float("inf"),
                "max": float("-inf"),
                "mean": 0,
                "std": 0
            }
            all_params = torch.cat([p.view(-1) for p in model.parameters()])
            param_stats["min"] = all_params.min().item()
            param_stats["max"] = all_params.max().item()
            param_stats["mean"] = all_params.mean().item()
            param_stats["std"] = all_params.std().item()
            print(f"Parameter stats - Min: {param_stats['min']:.5f}, Max: {param_stats['max']:.5f}, Mean: {param_stats['mean']:.5f}, Std: {param_stats['std']:.5f}")


L2 Regularization
^^^^^^^^^^^^^^^^^^

.. step::
    1) Ajoutez une r√©gularisation L2 (weight decay) √† votre optimiseur avec un coefficient de 0.01.

.. step::
    2) Entra√Ænez √† nouveau le mod√®le avec cette r√©gularisation et comparez les performances obtenues avec celles sans r√©gularisation.

L1 Regularization
^^^^^^^^^^^^^^^^^^

.. step::
    3) Enlevez la r√©gularisation L2 et ajoutez une r√©gularisation L1 √† votre fonction de co√ªt avec un coefficient de 0.001.

.. step::
    4) Entra√Ænez √† nouveau le mod√®le avec cette r√©gularisation et comparez les performances obtenues avec celles sans r√©gularisation.

Dropout
^^^^^^^^

.. step::
    3) Enlevez la r√©gularisation L1 et ajoutez une couche de Dropout √† votre r√©seau de neurones avec un taux de 0.5 entre les convolutions (C1 et C2) et entre les deux premi√®res couches fully connected (F3 et F4).

.. step::
    4) Entra√Ænez √† nouveau le mod√®le avec cette r√©gularisation et comparez les performances obtenues avec celles sans r√©gularisation.

Exercice 6 : Learning Rate Scheduler
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Le learning rate (taux d'apprentissage) fix√© √† l'exercice 3 est peut √™tre trop √©lev√©... 0.001 serait sans doute trop faible... 0.01 serait peut √™tre un bon compromis ?

En r√©alit√©, nous n'en savons rien et il vaut mieux √©viter de faire des suppositions. L'id√©al sera en fait de commencer par une valeur suffisamment √©lev√©e, puis corriger (diminuer) cette valeur au fur et √† mesure de l'entra√Ænement.

.. step::
    1) Impl√©mentez le scheduler ``torch.optim.lr_scheduler.ReduceLROnPlateau`` dans votre boucle d'entra√Ænement.

.. step::
    2) Relancez un entra√Ænement en affichant la valeur du learning rate √† chaque √©poque. Constatez l'√©volution de la loss en fonction des "paliers" du learning rate.

.. warning::
    ‚ö†Ô∏è Attention au r√©glage de la "patience" de la classe ``ReduceLROnPlateau`` qui ne doit pas √™tre en conflit avec celle de l'Early Stopping ! Voyez-vous pourquoi ?


Exercice 7 : Normalization 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. step::
    1) Ajoutez une couche de ``torch.nn.BatchNorm??`` entre les deux couches de convolution. Attention √† choisir la bonne version de la couche (nombre de dimenions) !
    
.. step::
    2) Affichez les valeurs min, max, mean et std des caract√©ristiques (features) des donn√©es avant et apr√®s la normalisation, puis relancez l'entra√Ænement. Que constatez-vous ?

Exercice 8 : Hyperparameter Tuning
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Jusqu'ici, nous avons utilis√© plusieurs techniques qui, th√©oriquement, am√©liorent les capacit√©s du mod√®le (sa performance, sa robustesse, ou son co√ªt d'entra√Ænement). Cependant, chaque technique n√©cessite un ou plusieurs choix d'algorithme (quelle normalisation ? quel scheduler ? etc.) et de param√®tres (taux de dropout, coefficient de r√©gularisation, etc.).

Vous avez sans doute pu constater qu'il est difficile de savoir quelle technique a un r√©el impact positif sur les performances du mod√®le pendant l'apprentissage et sur sa capacit√© √† g√©n√©raliser.

.. step::
    1) Cet exercice est libre et consiste √† tester diff√©rentes combinaisons de techniques et d'hyperparam√®tres pour am√©liorer les performances de votre mod√®le sur le jeu de validation. Que vous cherchiez manuellement ou que vous utilisiez une m√©thode automatique, essayez d√©sormais de maximiser les performances de votre r√©seau !

.. note::
    üß† **Rappel:**

    1. D√©finir un espace d'hyperparam√®tres √† explorer 
    2. D√©finir une fonction objectif (par exemple, maximiser l'accuracy sur le jeu de validation)
    3. Pour chaque combinaison d'hyperparam√®tres test√©e, entra√Æner un mod√®le et √©valuer ses performances sur le jeu de validation
    4. Garder en m√©moire la meilleure combinaison d'hyperparam√®tres trouv√©e

    **Conseil: ** Lorsque le nombre de possibilit√©s est trop important, vous pouvez commencer par un d√©finir un espace de recherche avec uniquement les hyperparam√®tres les plus influents. Cette premi√®re recherche permet donc de trouver une valeur optimale que vous pouvez fixer pour ceux-ci. Ensuite, une deuxi√®me phase de recherche peut √™tre lanc√©e en incluant les autres hyperparam√®tres. 
